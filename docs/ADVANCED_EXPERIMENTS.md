# Advanced Model Experiments Guide

ê³ ê¸‰ ëª¨ë¸ ì‹¤í—˜ì„ ìœ„í•œ ê°€ì´ë“œ ë° ë¦¬ì†ŒìŠ¤

## ğŸ“š ê°œìš”

ì´ ë¬¸ì„œëŠ” Stage 4 ì´í›„ ì¶”ê°€ì ì¸ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ê³ ê¸‰ ì‹¤í—˜ ê¸°ë²•ë“¤ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ”¬ ì‹¤í—˜ ê°€ëŠ¥í•œ ê¸°ë²•ë“¤

### 1. ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ í™œìš©

#### Qwen2.5 ì‹œë¦¬ì¦ˆ
```python
# Qwen2.5-7B-Instruct í™œìš©
from transformers import AutoTokenizer, AutoModelForCausalLM

model_name = "Qwen/Qwen2.5-7B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto"
)

# Few-shot prompting
prompt = f"""ë‹¤ìŒ ëŒ€í™”ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:

{dialogue}

ìš”ì•½:"""

inputs = tokenizer(prompt, return_tensors="pt").to("cuda")
outputs = model.generate(**inputs, max_new_tokens=128)
summary = tokenizer.decode(outputs[0], skip_special_tokens=True)
```

#### Solar API í™œìš©
```python
import requests
import os

SOLAR_API_KEY = os.getenv("SOLAR_API_KEY")

def generate_summary_with_solar(dialogue):
    url = "https://api.upstage.ai/v1/solar/chat/completions"

    headers = {
        "Authorization": f"Bearer {SOLAR_API_KEY}",
        "Content-Type": "application/json"
    }

    payload = {
        "model": "solar-1-mini-chat",
        "messages": [
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ í•œêµ­ì–´ ëŒ€í™”ë¥¼ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
            },
            {
                "role": "user",
                "content": f"ë‹¤ìŒ ëŒ€í™”ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:\\n\\n{dialogue}"
            }
        ],
        "temperature": 0.3
    }

    response = requests.post(url, headers=headers, json=payload)
    return response.json()["choices"][0]["message"]["content"]
```

### 2. Parameter Efficient Fine-Tuning (PEFT)

#### LoRA ì„¤ì • ìµœì í™”
```python
from peft import LoraConfig, get_peft_model, TaskType

# ë” ê³µê²©ì ì¸ LoRA ì„¤ì •
lora_config = LoraConfig(
    r=16,  # Increased rank
    lora_alpha=32,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],  # More modules
    lora_dropout=0.05,
    bias="none",
    task_type=TaskType.SEQ_2_SEQ_LM
)

model = get_peft_model(base_model, lora_config)
```

#### QLoRA (4-bit quantization)
```python
from transformers import BitsAndBytesConfig

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16
)

model = AutoModelForSeq2SeqLM.from_pretrained(
    model_name,
    quantization_config=bnb_config,
    device_map="auto"
)
```

### 3. ì•™ìƒë¸” ê¸°ë²•

#### Weighted Voting
```python
def weighted_ensemble(predictions_list, weights):
    \"\"\"ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì•™ìƒë¸”.\"\"\"
    from collections import Counter

    ensembled = []
    for preds in zip(*predictions_list):
        # Count votes with weights
        vote_counter = Counter()
        for pred, weight in zip(preds, weights):
            vote_counter[pred] += weight

        # Get winner
        winner = vote_counter.most_common(1)[0][0]
        ensembled.append(winner)

    return ensembled

# Example
weights = [0.4, 0.35, 0.25]  # Based on validation ROUGE scores
final_predictions = weighted_ensemble(
    [kobart_preds, mbart_preds, qwen_preds],
    weights
)
```

#### Stacking Ensemble
```python
from sklearn.linear_model import Ridge

def stacking_ensemble(base_predictions, meta_features, val_labels):
    \"\"\"ìŠ¤íƒœí‚¹ ì•™ìƒë¸” with meta-learner.\"\"\"

    # Train meta-learner
    meta_model = Ridge(alpha=1.0)
    meta_model.fit(meta_features, val_labels)

    # Predict
    final_predictions = meta_model.predict(test_meta_features)

    return final_predictions
```

### 4. ë°ì´í„° ì¦ê°•

#### Back-Translation
```python
from transformers import pipeline

# Korean -> English -> Korean
ko_to_en = pipeline("translation", model="Helsinki-NLP/opus-mt-ko-en")
en_to_ko = pipeline("translation", model="Helsinki-NLP/opus-mt-en-ko")

def back_translate(text):
    en_text = ko_to_en(text)[0]['translation_text']
    ko_text = en_to_ko(en_text)[0]['translation_text']
    return ko_text

augmented_dialogues = [back_translate(d) for d in train_df['dialogue']]
```

#### Paraphrasing
```python
# Use GPT models for paraphrasing
def paraphrase_with_gpt(text):
    prompt = f"ë‹¤ìŒ ë¬¸ì¥ì„ ë‹¤ë¥´ê²Œ í‘œí˜„í•´ì£¼ì„¸ìš”: {text}"
    # Use Solar or other API
    return generated_paraphrase
```

### 5. Post-processing

#### ê¸¸ì´ ì œì•½ ì ìš©
```python
def apply_length_constraint(summary, max_length=150):
    \"\"\"ìš”ì•½ë¬¸ ê¸¸ì´ ì œì•½.\"\"\"
    if len(summary) > max_length:
        # Truncate at sentence boundary
        sentences = summary.split('.')
        truncated = ''
        for sent in sentences:
            if len(truncated + sent + '.') <= max_length:
                truncated += sent + '.'
            else:
                break
        return truncated.strip()
    return summary
```

#### ë°˜ë³µ ì œê±°
```python
import re

def remove_repetitions(text):
    \"\"\"ë°˜ë³µ êµ¬ë¬¸ ì œê±°.\"\"\"
    # Remove repeated phrases
    words = text.split()
    seen = set()
    filtered = []

    for i, word in enumerate(words):
        # Check 3-gram repetition
        if i >= 2:
            trigram = ' '.join(words[i-2:i+1])
            if trigram in seen:
                continue
            seen.add(trigram)
        filtered.append(word)

    return ' '.join(filtered)
```

## ğŸ“Š ì‹¤í—˜ ì¶”ì 

### WandB Sweepìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰
```yaml
# sweep_config.yaml
program: notebooks/stage4_advanced_models.ipynb
method: bayes
metric:
  name: rouge_sum
  goal: maximize
parameters:
  lora_r:
    values: [8, 16, 32]
  lora_alpha:
    values: [16, 32, 64]
  learning_rate:
    min: 1e-5
    max: 5e-5
  num_train_epochs:
    values: [3, 5, 7]
```

```bash
# Run sweep
wandb sweep sweep_config.yaml
wandb agent <sweep_id>
```

## ğŸš€ ì‹¤í–‰ ì˜ˆì‹œ

### Context7ì„ í™œìš©í•œ ëª¨ë¸ ë¬¸ì„œ ê²€ìƒ‰
```python
# MCP context7 tool ì‚¬ìš© ì˜ˆì‹œ
# íŠ¹ì • ëª¨ë¸ì˜ ìµœì‹  ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ì—¬ ìµœì  ì„¤ì • ì°¾ê¸°

# 1. Qwen2.5 ê³µì‹ ë¬¸ì„œ ê²€ìƒ‰
# 2. LoRA ìµœì  ì„¤ì • ì°¾ê¸°
# 3. í•œêµ­ì–´ ì„±ëŠ¥ í–¥ìƒ ê¸°ë²• ì¡°ì‚¬
```

## ğŸ“ ì‹¤í—˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Qwen2.5-7B-Instruct ì‹¤í—˜
- [ ] Solar API í†µí•© í…ŒìŠ¤íŠ¸
- [ ] QLoRA 4-bit ì–‘ìí™” ì ìš©
- [ ] 3-model ì•™ìƒë¸” êµ¬ì„±
- [ ] Back-translation ë°ì´í„° ì¦ê°•
- [ ] Post-processing íŒŒì´í”„ë¼ì¸ ì ìš©
- [ ] WandB Sweep ì‹¤í–‰
- [ ] ìµœì¢… ROUGE > 80 ë‹¬ì„±

## ğŸ¯ ëª©í‘œ

- **Baseline (KoBART)**: ROUGE ~70
- **Optimized (Stage 3)**: ROUGE ~75
- **Advanced (Stage 4)**: ROUGE ~78-80
- **Target**: ROUGE > 80 âœ¨

## ğŸ“š ì°¸ê³  ìë£Œ

- [Qwen2.5 Documentation](https://qwenlm.github.io/)
- [LoRA Paper](https://arxiv.org/abs/2106.09685)
- [QLoRA Paper](https://arxiv.org/abs/2305.14314)
- [PEFT Library](https://github.com/huggingface/peft)
- [Korean NLP Resources](https://github.com/gyunggyung/Korean-NLP)
