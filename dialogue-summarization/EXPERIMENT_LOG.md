# ğŸ§ª ì‹¤í—˜ ê¸°ë¡ (Experiment Log)

> í•œêµ­ì–´ ëŒ€í™” ìš”ì•½ ëª¨ë¸ ì‹¤í—˜ ê²°ê³¼ ì¶”ì 

## ğŸ“Š Baseline ì ìˆ˜

| ì§€í‘œ | ì ìˆ˜ | ë¹„ê³  |
|------|------|------|
| **ROUGE-1** | **0.5660** | Baseline |
| **ROUGE-2** | **0.3675** | Baseline |
| **ROUGE-L** | **0.4719** | Baseline |
| **Final Score** | **46.8487** | Baseline |

---

## ğŸ“ˆ ì‹¤í—˜ ê²°ê³¼

### Experiment #1: Baseline (Modular Structure)

**ë‚ ì§œ**: 2025-10-01
**ëª¨ë¸**: `digit82/kobart-summarization`
**ì²´í¬í¬ì¸íŠ¸**: `checkpoint-1750` (Epoch 7, Best Model)

#### ì„¤ì •
```yaml
model: digit82/kobart-summarization
num_train_epochs: 20
per_device_train_batch_size: 50
per_device_eval_batch_size: 32
learning_rate: 1.0e-5
warmup_ratio: 0.1
lr_scheduler_type: cosine
max_input_length: 512
max_output_length: 100
```

#### í•™ìŠµ ê²°ê³¼ (Dev Set)
- ROUGE-1: 32.28
- ROUGE-2: 13.46
- ROUGE-L: 30.03
- ROUGE Sum: **75.77**

#### ì œì¶œ ê²°ê³¼ (Test Set)
| ì§€í‘œ | ì ìˆ˜ | ë³€í™” |
|------|------|------|
| ROUGE-1 | 0.5660 | **Baseline** |
| ROUGE-2 | 0.3675 | **Baseline** |
| ROUGE-L | 0.4719 | **Baseline** |
| **Final Score** | **46.8487** | **Baseline** |

#### íŠ¹ì§•
- âœ… Java/konlpy ì˜ì¡´ì„± ì œê±° (rouge ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)
- âœ… ëª¨ë“ˆí™”ëœ ì½”ë“œ êµ¬ì¡°
- âœ… Early stopping ì ìš© (Epoch 7ì—ì„œ best model)
- âœ… Type hints & Docstrings ì™„ë¹„

#### ê°œì„ ì 
- [ ] Hyperparameter tuning (learning rate, batch size)
- [ ] Longer training (ë” ë§ì€ epoch)
- [ ] Advanced models (mBART, KoGPT ë“±)
- [ ] Data augmentation
- [ ] Ensemble ì „ëµ

---

### Experiment #2: Model Screening (Zero-shot Evaluation)

**ë‚ ì§œ**: 2025-10-02
**ëª©ì **: ì—¬ëŸ¬ í•œêµ­ì–´ ìš”ì•½ ëª¨ë¸ì˜ Zero-shot ì„±ëŠ¥ ë¹„êµ
**ë°©ë²•**: Fine-tuning ì—†ì´ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ë¡œ Dev Set í‰ê°€

#### í…ŒìŠ¤íŠ¸ ëª¨ë¸ (4ê°œ)
1. `gogamza/kobart-base-v2` - SKT KoBART base model
2. `ainize/kobart-news` - News summarization specialized
3. `psyche/KoT5-summarization` - T5 Korean summarization
4. `digit82/kobart-summarization` - Current baseline model

#### ìŠ¤í¬ë¦¬ë‹ ê²°ê³¼ (Dev Set, Zero-shot)

| ëª¨ë¸ | ROUGE-1 | ROUGE-2 | ROUGE-L | ROUGE Sum | ìƒíƒœ |
|------|---------|---------|---------|-----------|------|
| **KoT5-sum** | **10.04** | **3.18** | **9.51** | **22.74** | âœ… Success |
| KoBART-sum | 8.34 | 2.19 | 7.75 | 18.27 | âœ… Success |
| KoBART-base | 3.74 | 0.61 | 3.62 | 7.97 | âœ… Success |
| KoBART-news | 0.00 | 0.00 | 0.00 | 0.00 | âŒ Failed (tokenizer error) |

#### ì„¤ì •
```yaml
inference:
  batch_size: 16
  num_beams: 4
  no_repeat_ngram_size: 2
  early_stopping: true
  generate_max_length: 100

disk_management:
  auto_cleanup_cache: true  # ëª¨ë¸ë³„ ìˆœì°¨ ì‹¤í–‰ & ìºì‹œ ì‚­ì œ
  max_disk_usage_gb: 80
```

#### ë¶„ì„
- âœ… **ìµœê³  ëª¨ë¸**: `psyche/KoT5-summarization` (ROUGE Sum 22.74)
  - T5 ê¸°ë°˜ ëª¨ë¸ì´ BART ê¸°ë°˜ë³´ë‹¤ Zero-shot ì„±ëŠ¥ ìš°ìˆ˜
  - Fine-tuning ì‹œ ë” í° ì„±ëŠ¥ í–¥ìƒ ê¸°ëŒ€
- âœ… **Fine-tuning íš¨ê³¼ í™•ì¸**:
  - KoBART-sum Zero-shot: 18.27 â†’ Fine-tuned: 75.77 (4.1ë°° í–¥ìƒ)
  - Fine-tuningì´ í•„ìˆ˜ì ì„ì„ ì¬í™•ì¸
- âš ï¸ **ëª¨ë¸ ì„ íƒ ì „ëµ**:
  - Zero-shot ì„±ëŠ¥ì´ ë†’ì€ ëª¨ë¸ = Fine-tuning ì„±ëŠ¥ë„ ë†’ì„ ê°€ëŠ¥ì„±
  - KoT5-sumì„ ë‹¤ìŒ Fine-tuning í›„ë³´ë¡œ ì„ ì •

#### ê°œì„ ì 
- [ ] KoT5-sum ëª¨ë¸ Fine-tuning ì‹¤í—˜
- [ ] ë” í° ëª¨ë¸ (mBART, KoGPT ë“±) ìŠ¤í¬ë¦¬ë‹ (ë””ìŠ¤í¬ ì œì•½ ê³ ë ¤)
- [ ] Ensemble ì „ëµ (KoT5 + KoBART)

---

### Experiment #3: Large LLM Screening (4bit QLoRA + TF32)

**ë‚ ì§œ**: 2025-10-03
**ëª©ì **: ëŒ€í˜• í•œêµ­ì–´ LLMì˜ Zero-shot ìš”ì•½ ì„±ëŠ¥ ë¹„êµ (Decoder-only models)
**ë°©ë²•**: 4bit ì–‘ìí™” + TF32 ìµœì í™”ë¡œ Zero-shot í‰ê°€

#### í…ŒìŠ¤íŠ¸ ëª¨ë¸ (4ê°œ)
1. `Qwen/Qwen2.5-7B-Instruct` - Qwen 7B ëª¨ë¸
2. `MLP-KTLim/llama-3-Korean-Bllossom-8B` - Llama 3 Korean 8B
3. `Bllossom/llama-3.2-Korean-Bllossom-3B` - Llama 3.2 Korean 3B
4. `upstage/SOLAR-10.7B-Instruct-v1.0` - SOLAR 10.7B

#### ìŠ¤í¬ë¦¬ë‹ ê²°ê³¼ (Dev Set, Zero-shot)

| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | ROUGE-1 | ROUGE-2 | ROUGE-L | ROUGE Sum | ì¶”ë¡  ì‹œê°„ | ìƒíƒœ |
|------|---------|---------|---------|---------|-----------|----------|------|
| **Llama-3.2-Korean-3B** ğŸ¥‡ | **3.21B** | **1.73** | **0.11** | **1.71** | **3.56** | **10ë¶„** | âœ… Success |
| Llama-3-Korean-8B | 8.03B | 1.16 | 0.03 | 1.14 | 2.33 | 25ë¶„ | âœ… Success |
| Qwen2.5-7B | 7.61B | 0.61 | 0.05 | 0.61 | 1.27 | 33ë¶„ | âœ… Success |
| SOLAR-10.7B | 10.73B | 0.00 | 0.00 | 0.00 | 0.00 | 11ì‹œê°„ | âŒ Failed (ë¹ˆ ìš”ì•½ ìƒì„±) |

#### ì„¤ì •
```yaml
qlora:
  load_in_4bit: true
  bnb_4bit_compute_dtype: bfloat16
  bnb_4bit_quant_type: nf4
  bnb_4bit_use_double_quant: true

inference:
  batch_size: 16
  num_beams: 4
  no_repeat_ngram_size: 2
  early_stopping: true
  generate_max_length: 100

optimization:
  tf32: true  # RTX 3090 Ampere ìµœì í™”
  flash_attention_2: false  # ì§§ì€ ì‹œí€€ìŠ¤(~500í† í°)ì—ì„œ íš¨ê³¼ ë¯¸ë¯¸
```

#### ë¶„ì„
- âœ… **ì••ë„ì  ìŠ¹ì**: `Llama-3.2-Korean-3B`
  - **ê°€ì¥ ì‘ì€ ëª¨ë¸**ì¸ë° **ê°€ì¥ ë†’ì€ ì„±ëŠ¥** (ROUGE Sum 3.56)
  - 2ìœ„(Llama-8B) ëŒ€ë¹„ **53% ë†’ì€ ì„±ëŠ¥**
  - **ê°€ì¥ ë¹ ë¥¸ ì¶”ë¡ ** (10ë¶„, ë°°ì¹˜ë‹¹ 20ì´ˆ)
  - ëª¨ë¸ í¬ê¸° â‰  ì„±ëŠ¥ (3B > 8B > 7B > 10.7B)

- âš ï¸ **SOLAR-10.7B ì™„ì „ ì‹¤íŒ¨**:
  - 11ì‹œê°„ 22ë¶„ ì†Œìš” (ë°°ì¹˜ë‹¹ 22ë¶„!)
  - ë¹ˆ ìš”ì•½ ìƒì„± â†’ ROUGE 0.00
  - ì—ëŸ¬: "Hypothesis is empty"
  - ì›ì¸ ì¶”ì •: í”„ë¡¬í”„íŠ¸ í˜•ì‹ ë¶ˆì¼ì¹˜ ë˜ëŠ” ê¸´ ì¶”ë¡  ì‹œê°„ìœ¼ë¡œ ì¸í•œ ë¬¸ì œ

- ğŸ“Š **Encoder-Decoder vs Decoder-only ë¹„êµ**:
  - KoT5-sum (Exp #2): ROUGE Sum 22.74 (Zero-shot)
  - Llama-3.2-3B (Exp #3): ROUGE Sum 3.56 (Zero-shot)
  - **Encoder-Decoder ëª¨ë¸ì´ ìš”ì•½ íƒœìŠ¤í¬ì— ë” ì í•©**
  - Decoder-onlyëŠ” Fine-tuning í•„ìˆ˜

- ğŸ’¡ **ìµœì í™” ì¸ì‚¬ì´íŠ¸**:
  - FlashAttention2: ì§§ì€ ì‹œí€€ìŠ¤(512+100í† í°)ì—ì„œ íš¨ê³¼ ê±°ì˜ ì—†ìŒ (1.1~1.2ë°°)
  - TF32: RTX 3090ì—ì„œ ì•ˆì •ì ì¸ ì†ë„ í–¥ìƒ (1.5~2ë°° ì¶”ì •)
  - 4bit ì–‘ìí™”: ë©”ëª¨ë¦¬ íš¨ìœ¨ ê·¹ëŒ€í™”, ì†ë„ë„ ê°œì„ 

#### ë‹¤ìŒ ë‹¨ê³„
- [ ] Llama-3.2-Korean-3B QLoRA Fine-tuning
- [ ] KoT5-sum Fine-tuning (ì´ì „ ì‹¤í—˜ì—ì„œ Zero-shot ìµœê³ )
- [ ] Llama vs KoT5 ì„±ëŠ¥ ë¹„êµ

#### W&B ë§í¬
- https://wandb.ai/bkan-ai/dialogue-summarization-screening/runs/xyhzikrq

#### ê²°ê³¼ íŒŒì¼
- `screening_results/screening_results_20251003_075909.csv`

---

### Experiment #3.1: Fixed LLM Screening (Mecab + Foreign Language Blocking)

**ë‚ ì§œ**: 2025-10-03
**ëª©ì **: Experiment #3ì˜ ë¬¸ì œì  í•´ê²° ë° ì¬í‰ê°€
**ë°©ë²•**: Mecab í˜•íƒœì†Œ í† í°í™” + bad_words_ids ì™¸êµ­ì–´ ì°¨ë‹¨ ì ìš©

#### ë¬¸ì œì  ë°œê²¬ (Experiment #3)
1. âŒ **í† í°í™” ë°©ì‹ ì˜¤ë¥˜**:
   - ë¬¸ì ê¸°ë°˜ í† í°í™” ì‚¬ìš© â†’ ROUGE ì ìˆ˜ **ê³¼ëŒ€í‰ê°€** (79.21 vs 51.13)
   - ëŒ€íšŒ ê³µì‹ í‰ê°€: **Mecab í˜•íƒœì†Œ ê¸°ë°˜** í† í°í™”
   - ì‹¤ì œ ì ìˆ˜ëŠ” ì•½ **65% ë‚®ìŒ**

2. âŒ **ì™¸êµ­ì–´ ìƒì„± ë¬¸ì œ**:
   - Zero-shot ìš”ì•½ì— ì˜ì–´/ì¼ë³¸ì–´/ì¤‘êµ­ì–´ í˜¼ì…
   - ì˜ˆì‹œ: "especialmente", "ç­”ç­”", "å†œêµ¬", "Ä‘áº·c biá»‡t"
   - í•œêµ­ì–´ ì „ìš© ìš”ì•½ ì‹¤íŒ¨

#### í•´ê²° ë°©ì•ˆ í…ŒìŠ¤íŠ¸ ê²°ê³¼

**í…ŒìŠ¤íŠ¸ ëª¨ë¸**: `Bllossom/llama-3.2-Korean-Bllossom-3B` (Dev Set, 499 samples)

| ë°©ì‹ | ROUGE-1 | ROUGE-2 | ROUGE-L | ROUGE Sum | ì™¸êµ­ì–´ ì°¨ë‹¨ | ì¶”ë¡  ì‹œê°„ | ìƒíƒœ |
|------|---------|---------|---------|-----------|------------|----------|------|
| ê¸°ë³¸ (Mecab) | 25.19 | 4.21 | 21.51 | **51.13** | âŒ ë‹¤ìˆ˜ í¬í•¨ | 10ë¶„ | âœ… Baseline |
| Enhanced Prompt | 22.42 | 3.17 | 19.51 | 45.09 | âŒ ì—¬ì „íˆ í¬í•¨ | 10ë¶„ | âŒ ì„±ëŠ¥ ì €í•˜ |
| bad_words_ids (ë¼í‹´+ì¼ë³¸ì–´) | 24.75 | 4.00 | 21.37 | 50.12 | âš ï¸ ì¼ë¶€ í¬í•¨ | 10ë¶„ | âš ï¸ ë¯¸í¡ |
| **bad_words_ids + CJK í•œì** | **25.19** | **4.21** | **21.51** | **50.92** | **âœ… ëŒ€ë¶€ë¶„ ì°¨ë‹¨** | **10ë¶„** | **âœ… ì±„íƒ** |
| LogitsProcessor | 24.54 | 3.77 | 20.98 | 49.28 | âŒ í•œì ëˆ„ë½ | **58ë¶„** | âŒ ë„ˆë¬´ ëŠë¦¼ |

#### ìµœì¢… ì„ íƒ: bad_words_ids + CJK ë°©ì‹

**êµ¬í˜„ ë‚´ìš©**:
```python
def generate_bad_words_ids(tokenizer):
    bad_ids = []
    for token_id in range(len(tokenizer)):
        token_str = tokenizer.decode([token_id])
        for ch in token_str:
            code = ord(ch)
            # ë¼í‹´ (A-Z, a-z, í™•ì¥)
            if 0x41 <= code <= 0x5A or 0x61 <= code <= 0x7A or 0x00C0 <= code <= 0x024F:
                bad_ids.append([token_id])
            # íˆë¼ê°€ë‚˜/ê°€íƒ€ì¹´ë‚˜
            elif 0x3040 <= code <= 0x30FF:
                bad_ids.append([token_id])
            # CJK í†µí•© í•œì
            elif 0x4E00 <= code <= 0x9FFF:
                bad_ids.append([token_id])
    return bad_ids  # ì•½ 2644ê°œ í† í° ì°¨ë‹¨
```

#### ë¶„ì„
- âœ… **Mecab í† í°í™” ì ìš©**: ëŒ€íšŒ ê³µì‹ í‰ê°€ ë°©ì‹ ì¤€ìˆ˜
- âœ… **ì™¸êµ­ì–´ ì°¨ë‹¨ ì„±ê³µ**: bad_words_ids + CJKê°€ ê°€ì¥ íš¨ê³¼ì 
- âœ… **ì„±ëŠ¥ ìœ ì§€**: ROUGE Sum 50.92 (baseline ëŒ€ë¹„ -0.21, 0.4% ì°¨ì´)
- âœ… **ì¶”ë¡  ì†ë„**: ë°°ì¹˜ë‹¹ 20ì´ˆë¡œ ë¹ ë¦„ (LogitsProcessor ëŒ€ë¹„ 5.5ë°°)
- âš ï¸ **í”„ë¡¬í”„íŠ¸ ê°œì„  ì‹¤íŒ¨**: Enhanced promptê°€ ì˜¤íˆë ¤ ì„±ëŠ¥ ì €í•˜ (-6.04)

#### ë‹¤ìŒ ë‹¨ê³„
- [ ] 5ê°œ ëª¨ë¸ í’€ ìŠ¤í¬ë¦¬ë‹ (Mecab + bad_words_ids + CJK ì ìš©)
  - Qwen/Qwen2.5-7B-Instruct
  - MLP-KTLim/llama-3-Korean-Bllossom-8B
  - Bllossom/llama-3.2-Korean-Bllossom-3B
  - Bllossom/llama-3.2-Korean-Bllossom-AICA-5B
  - upstage/SOLAR-10.7B-Instruct-v1.0
- [ ] ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ ì • ë° QLoRA Fine-tuning

#### ê¸°ìˆ ì  ê°œì„ ì‚¬í•­
```yaml
# metrics.py - Mecab í† í°í™” ì¶”ê°€
tokenization_mode: 'mecab'  # 'char' ëŒ€ì‹  'mecab' ì‚¬ìš©

# model_screening.py - ì™¸êµ­ì–´ ì°¨ë‹¨
inference:
  bad_words_ids: generate_bad_words_ids(tokenizer)  # 2644ê°œ í† í° ì°¨ë‹¨

optimization:
  tf32: true
  qlora_4bit: true
```

---

### Experiment #3.2: Final LLM Screening (5 Models + Qwen3-4B)

**ë‚ ì§œ**: 2025-10-04
**ëª¨ë¸**: 5ê°œ í•œêµ­ì–´ LLM (QLoRA 4bit + TF32 ìµœì í™”)

#### ì„¤ì •
- Quantization: QLoRA 4bit (NF4)
- Batch Size: 16
- Max Length: 512 (input) / 100 (output)
- Beam Search: 4
- Foreign Token Blocking: bad_words_ids (121k+ tokens)
- Tokenizer: Mecab morphological tokenization for ROUGE

#### Zero-shot í‰ê°€ ê²°ê³¼ (Dev Set, 499 samples)

| ìˆœìœ„ | ëª¨ë¸ | ROUGE-1 | ROUGE-2 | ROUGE-L | **ROUGE Sum** | íŒŒë¼ë¯¸í„° |
|------|------|---------|---------|---------|---------------|----------|
| ğŸ¥‡ | **Llama-3.2-Korean-3B** | 24.72 | 3.73 | 21.07 | **49.52** | 3.21B |
| ğŸ¥ˆ | Llama-3-Korean-8B | 23.95 | 4.01 | 20.65 | **48.61** | 8.03B |
| ğŸ¥‰ | Qwen2.5-7B | 23.34 | 4.05 | 19.45 | **46.84** | 7.61B |
| 4 | Qwen3-4B-Instruct-2507 | 22.60 | 3.54 | 18.88 | **45.02** | 4.02B |
| 5 | Llama-3.2-Korean-AICA-5B | 21.22 | 2.91 | 17.86 | **41.99** | 4.31B |

**Notes**:
- SOLAR-10.7B aborted (40x slower due to depth upscaling architecture)
- Llama-3.2-3B achieved best zero-shot performance despite smallest size
- AICA-5B underperformed due to task misalignment (trained for conversation generation)

#### í•µì‹¬ ë°œê²¬
1. **ëª¨ë¸ í¬ê¸° â‰  ì„±ëŠ¥**: 3.21B ëª¨ë¸ì´ 8B ëª¨ë¸ì„ ëŠ¥ê°€
2. **Task Alignment ì¤‘ìš”**: Instruction-tuned > Conversation-specialized
3. **Fine-tuning í›„ë³´**: Llama-3.2-3B (1ìˆœìœ„), Llama-3-8B (2ìˆœìœ„)

---

## ğŸ¯ ë‹¤ìŒ ì‹¤í—˜ ê³„íš

### Experiment #4: KoT5 Fine-tuning (ìš°ì„ ìˆœìœ„ 1)
- ëª¨ë¸: `psyche/KoT5-summarization`
- Zero-shot ìµœê³  ì„±ëŠ¥ (ROUGE Sum 22.74) - Encoder-Decoder ì•„í‚¤í…ì²˜
- ëª©í‘œ: Final Score > 48.0 (+1.15)

### Experiment #5: Llama-3.2-Korean-3B QLoRA Fine-tuning (ìš°ì„ ìˆœìœ„ 2)
- ëª¨ë¸: `Bllossom/llama-3.2-Korean-Bllossom-3B`
- LLM ì¤‘ Zero-shot ìµœê³  (ROUGE Sum 3.56) - Decoder-only ì•„í‚¤í…ì²˜
- QLoRA 4bit Fine-tuning ì ìš©
- ëª©í‘œ: Decoder-only ëª¨ë¸ì˜ Fine-tuning íš¨ê³¼ ê²€ì¦

### Experiment #6: Learning Rate Tuning
- learning_rate: 5e-6, 3e-5, 5e-5 ì‹œë„
- ëª©í‘œ: Fine-tuning ìµœì í™”

### Experiment #7: Ensemble Strategy
- KoT5-sum + Llama-3.2-3B ì•™ìƒë¸”
- ëª©í‘œ: Encoder-Decoderì™€ Decoder-only ë‹¤ì–‘ì„± í™•ë³´

---

## ğŸ“ ì‹¤í—˜ í…œí”Œë¦¿

### Experiment #N: [ì‹¤í—˜ëª…]

**ë‚ ì§œ**: YYYY-MM-DD
**ëª¨ë¸**: [ëª¨ë¸ëª…]
**ì²´í¬í¬ì¸íŠ¸**: [ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ]

#### ì„¤ì •
```yaml
[ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°]
```

#### í•™ìŠµ ê²°ê³¼ (Dev Set)
- ROUGE-1: XX.XX
- ROUGE-2: XX.XX
- ROUGE-L: XX.XX
- ROUGE Sum: XX.XX

#### ì œì¶œ ê²°ê³¼ (Test Set)
| ì§€í‘œ | ì ìˆ˜ | ë³€í™” |
|------|------|------|
| ROUGE-1 | X.XXXX | (+/-X.XXXX) |
| ROUGE-2 | X.XXXX | (+/-X.XXXX) |
| ROUGE-L | X.XXXX | (+/-X.XXXX) |
| **Final Score** | **XX.XXXX** | **(+/-X.XXXX)** |

#### íŠ¹ì§•
- [ë³€ê²½ì‚¬í•­ 1]
- [ë³€ê²½ì‚¬í•­ 2]

#### ë¶„ì„
- [ì„±ëŠ¥ ë³€í™” ë¶„ì„]
- [ê°œì„ /ì•…í™” ì›ì¸ ë¶„ì„]

---

## ğŸ“Œ ë©”ëª¨

- **ìµœê³  ì ìˆ˜**: 46.8487 (Experiment #1)
- **ìµœê³  ROUGE-1**: 0.5660 (Experiment #1)
- **ìµœê³  ROUGE-2**: 0.3675 (Experiment #1)
- **ìµœê³  ROUGE-L**: 0.4719 (Experiment #1)
