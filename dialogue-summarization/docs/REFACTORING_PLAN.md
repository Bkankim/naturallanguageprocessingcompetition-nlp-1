# ğŸ”„ ë¦¬íŒ©í† ë§ ê³„íš: ë² ì´ìŠ¤ë¼ì¸ í†µí•© ì „ëµ

**ì‘ì„±ì¼**: 2025-10-05
**ëª©ì **: Korean_DCS_2024 ë² ì´ìŠ¤ë¼ì¸ì˜ í•µì‹¬ ìš”ì†Œë¥¼ í˜„ì¬ ì½”ë“œë² ì´ìŠ¤ì— í†µí•©í•˜ì—¬ ì„±ëŠ¥ ë° íš¨ìœ¨ì„± ê°œì„ 

---

## ğŸ“‹ Executive Summary

### í˜„ì¬ ìƒí™©
- **ìš°ë¦¬ ì„±ëŠ¥**: Llama-3.2-Korean-3B LR=1e-4 í•™ìŠµ ì™„ë£Œ, submission ìƒì„±
- **ëª©í‘œ**: koBART 94.51 ROUGE ìˆ˜ì¤€ ë‹¬ì„±
- **ë¬¸ì œì **:
  - LR 5ë°° ê³¼ë‹¤ (1e-4 vs ë² ì´ìŠ¤ë¼ì¸ 2e-5)
  - Grad_norm ë¶ˆì•ˆì • (2.76 spike)
  - Packing ë¯¸ì§€ì› (40-60% í† í° ë‚­ë¹„)
  - System prompt ì—­ì„¤ (ì™¸êµ­ì–´ ê¸ˆì§€ ì–¸ê¸‰ì´ ì˜¤íˆë ¤ íŠ¸ë¦¬ê±°)

### ì „ëµ
**í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼**: ì™„ì „ ì¬ì‘ì„± ëŒ€ì‹  **ì ì§„ì  í†µí•©**ìœ¼ë¡œ ë¦¬ìŠ¤í¬ ìµœì†Œí™”

---

## ğŸ¯ Phase 1: Config ìµœì í™” (ì¦‰ì‹œ ì ìš© ê°€ëŠ¥)

**ì†Œìš” ì‹œê°„**: 30ë¶„
**ë¦¬ìŠ¤í¬**: ë‚®ìŒ
**ì˜ˆìƒ íš¨ê³¼**: ê·¸ë˜ë””ì–¸íŠ¸ ì•ˆì •ì„± í™•ë³´, ì™¸êµ­ì–´ í˜¼ì… 50% ê°ì†Œ

### 1.1 Learning Rate ì¡°ì •

**ë³€ê²½ ì „** (`configs/finetune_config.yaml`):
```yaml
training:
  learning_rate: 1.0e-4  # âŒ 5ë°° ê³¼ë‹¤
```

**ë³€ê²½ í›„**:
```yaml
training:
  learning_rate: 2.0e-5  # âœ… ë² ì´ìŠ¤ë¼ì¸ ê¸°ì¤€
```

**ê·¼ê±°**:
- Korean_DCS_2024: `2e-5` ì‚¬ìš©
- í˜„ì¬ grad_norm spike (2.76) â†’ ë¶ˆì•ˆì •ì„± ì§€í‘œ
- 5ë°° ê°ì†Œë¡œ ìˆ˜ë ´ ì•ˆì •í™”

---

### 1.2 LR Scheduler ë³€ê²½

**ë³€ê²½ ì „**:
```yaml
training:
  lr_scheduler_type: "constant"  # âŒ ìˆ˜ë ´ í’ˆì§ˆ ì €í•˜
```

**ë³€ê²½ í›„**:
```yaml
training:
  lr_scheduler_type: "cosine"  # âœ… í›„ë°˜ ìˆ˜ë ´ ê°œì„ 
```

**ê·¼ê±°**:
- Cosine annealing: ë§ˆì§€ë§‰ ì—í­ì—ì„œ LRì„ 0ì— ê°€ê¹ê²Œ ê°ì†Œ
- Fine-tuningì—ì„œ í‘œì¤€ì ìœ¼ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥

---

### 1.3 Weight Decay ì¶”ê°€

**ë³€ê²½ ì „**:
```yaml
training:
  weight_decay: 0.0  # âŒ ê³¼ì í•© ìœ„í—˜
```

**ë³€ê²½ í›„**:
```yaml
training:
  weight_decay: 0.1  # âœ… ì •ê·œí™” ê°•í™”
```

---

### 1.4 Effective Batch Size ì¦ê°€

**ë³€ê²½ ì „**:
```yaml
training:
  per_device_train_batch_size: 8
  gradient_accumulation_steps: 4
  # Effective batch = 8 * 4 = 32
```

**ë³€ê²½ í›„**:
```yaml
training:
  per_device_train_batch_size: 8
  gradient_accumulation_steps: 8
  # Effective batch = 8 * 8 = 64 (ë² ì´ìŠ¤ë¼ì¸ê³¼ ë™ì¼)
```

**ê·¼ê±°**:
- ë” í° ë°°ì¹˜ í¬ê¸° â†’ ê·¸ë˜ë””ì–¸íŠ¸ ì¶”ì • ì•ˆì •ì„± í–¥ìƒ
- GPU ë©”ëª¨ë¦¬ í—ˆìš© ë²”ìœ„ ë‚´ (Llama 19.15GB, Qwen 23.04GB)

---

### 1.5 System Prompt ë‹¨ìˆœí™”

**ë³€ê²½ ì „** (âŒ ì—­ì„¤ì  ë¬¸ì œ):
```yaml
system_prompt: |
  ë‹¹ì‹ ì€ ëŒ€í™” ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
  ë‹¤ìŒ ì§€ì¹¨ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì„¸ìš”:

  - ë°˜ë“œì‹œ í•œêµ­ì–´ë§Œ ì‚¬ìš©í•˜ì„¸ìš” (ì˜ë¬¸/ì¼ë¬¸/ë² íŠ¸ë‚¨ì–´/ì´ëª¨ì§€/URL ê¸ˆì§€).  # â† ë¬¸ì œ!
  - ëŒ€í™”ì˜ í•µì‹¬ ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”.
  ...
```

**ë³€ê²½ í›„** (âœ… í—ˆìš©ì  ì ‘ê·¼):
```yaml
system_prompt: |
  ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
  ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
```

**ê·¼ê±°**:
- ë² ì´ìŠ¤ë¼ì¸ê³¼ ë™ì¼í•œ ë‹¨ìˆœ í”„ë¡¬í”„íŠ¸
- "ê¸ˆì§€" ì–¸ê¸‰ì´ multilingual token í™œì„±í™” ê°€ëŠ¥ì„± ì œê±°
- ì‘ì—… ì¸ì‹ì€ User promptì˜ [Question]ì—ì„œ ì²˜ë¦¬

---

## âš¡ Phase 1.5: ì¶”ê°€ Quick Wins (ì‹¬ì¸µ ë¶„ì„ ê²°ê³¼)

**ì‘ì„±ì¼**: 2025-10-05 (Korean_DCS_2024 ì‹¬ì¸µ ë¹„êµ ì™„ë£Œ)
**ì†Œìš” ì‹œê°„**: 30-60ë¶„
**ë¦¬ìŠ¤í¬**: ë‚®ìŒ
**ì˜ˆìƒ íš¨ê³¼**: ë©”ëª¨ë¦¬ íš¨ìœ¨ ê°œì„ , ì¬í˜„ì„± í™•ë³´

### 1.6 gradient_checkpointing_kwargs ì¶”ê°€ (ğŸ”¥ ì¦‰ì‹œ ì ìš©)

**ë³€ê²½ ì „** (`configs/finetune_config.yaml`):
```yaml
training:
  gradient_checkpointing: true  # use_reentrant ê¸°ë³¸ê°’ True (êµ¬ì‹)
```

**ë³€ê²½ í›„**:
```yaml
training:
  gradient_checkpointing: true
  gradient_checkpointing_kwargs:
    use_reentrant: false  # âœ… PyTorch 2.0+ ê¶Œì¥
```

**ê·¼ê±°**:
- **Korean_DCS_2024**: `gradient_checkpointing_kwargs={"use_reentrant": False}` ëª…ì‹œ
- PyTorch 2.0+ì—ì„œ `use_reentrant=False`ê°€ ê¶Œì¥ë¨
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ + ì•ˆì •ì„± ê°œì„ 
- ê¸°ë³¸ê°’ TrueëŠ” deprecated warning ë°œìƒ ê°€ëŠ¥

**ì˜í–¥ë„**: â­â­â­ High (ë©”ëª¨ë¦¬ ìµœì í™”)

**íŒŒì¼ ìˆ˜ì •**:
```bash
# configs/finetune_config.yaml Line 182 ìˆ˜ì •
vim configs/finetune_config.yaml
```

---

### 1.7 Package ë²„ì „ Korean_DCS_2024ì™€ ë™ê¸°í™” (ì„ íƒì )

**í˜„ì¬ ë²„ì „**:
```
transformers==4.57.0
peft==0.17.1
trl==0.23.1
```

**Korean_DCS_2024 ê²€ì¦ ë²„ì „**:
```
transformers==4.41.1
peft==0.11.1
trl==0.9.4
```

**ì°¨ì´ ë¶„ì„**:
| íŒ¨í‚¤ì§€ | í˜„ì¬ | ë² ì´ìŠ¤ë¼ì¸ | ë²„ì „ ì°¨ì´ | í˜¸í™˜ì„± ë¦¬ìŠ¤í¬ |
|--------|------|------------|-----------|---------------|
| transformers | 4.57.0 | 4.41.1 | +16 ë²„ì „ | âš ï¸ Medium (API ë³€ê²½ ê°€ëŠ¥) |
| peft | 0.17.1 | 0.11.1 | +6 ë²„ì „ | âš ï¸ Low (LoRA ë™ì‘ ì°¨ì´) |
| trl | 0.23.1 | 0.9.4 | +14 ë²„ì „ | âš ï¸âš ï¸ High (SFTTrainer ëŒ€í­ ë³€ê²½) |

**ê¶Œì¥ ì‚¬í•­**:
- **Option A (ë³´ìˆ˜ì )**: ë² ì´ìŠ¤ë¼ì¸ ë²„ì „ìœ¼ë¡œ ë‹¤ìš´ê·¸ë ˆì´ë“œ
  ```bash
  pip install transformers==4.41.1 peft==0.11.1 trl==0.9.4
  ```
  - ì¥ì : ë² ì´ìŠ¤ë¼ì¸ê³¼ ì™„ì „ ë™ì¼í•œ í™˜ê²½, ì¬í˜„ì„± ê·¹ëŒ€í™”
  - ë‹¨ì : ìµœì‹  ë²„ê·¸ íŒ¨ì¹˜ ëˆ„ë½

- **Option B (í˜„ìƒ ìœ ì§€)**: í˜„ì¬ ë²„ì „ ìœ ì§€, Phase 3 SFTTrainer ì ìš© ì‹œ ì£¼ì˜
  - ì¥ì : ìµœì‹  ë²„ê·¸ íŒ¨ì¹˜ ì ìš©
  - ë‹¨ì : ë² ì´ìŠ¤ë¼ì¸ê³¼ ë™ì‘ ì°¨ì´ ê°€ëŠ¥

**ê²°ì •**: Phase 1.5ëŠ” í˜„ì¬ ë²„ì „ ìœ ì§€, Phase 3 SFTTrainer ì ìš© ì‹œ í˜¸í™˜ì„± ê²€ì¦

---

### 1.8 warmup_steps vs warmup_ratio ë¹„êµ (ë¬¸ì„œí™”ë§Œ)

**í˜„ì¬ ì„¤ì •**:
```yaml
training:
  warmup_ratio: 0.1  # ì „ì²´ stepsì˜ 10%
```

**Korean_DCS_2024**:
```python
warmup_steps=args.warmup_steps  # ì ˆëŒ€ê°’ (ëª…ì‹œì )
```

**ì°¨ì´ì **:
- ìš°ë¦¬: warmup_ratio â†’ ë°ì´í„°ì…‹ í¬ê¸°ì— ë”°ë¼ ë³€ë™
- ë² ì´ìŠ¤ë¼ì¸: warmup_steps â†’ ê³ ì •ê°’, ì¬í˜„ì„± ë†’ìŒ

**ê³„ì‚° ì˜ˆì‹œ**:
- ì „ì²´ steps = 130 (12,457 / batch=8 / grad_accum=8 / 3 epochs)
- warmup_ratio=0.1 â†’ warmup_steps=13

**ê²°ë¡ **: í˜„ì¬ ì„¤ì • ìœ ì§€ (ìœ ì—°ì„± ìš°ì„ )

---

## ğŸ”§ Phase 2: Prompt êµ¬ì¡°í™” + Label Masking ê°œì„  (2-3ì‹œê°„)

**ì†Œìš” ì‹œê°„**: 1-2ì‹œê°„
**ë¦¬ìŠ¤í¬**: ì¤‘ê°„ (ì½”ë“œ ìˆ˜ì • í•„ìš”)
**ì˜ˆìƒ íš¨ê³¼**: ROUGE +5~10

### 2.1 ë² ì´ìŠ¤ë¼ì¸ Prompt Format ì ìš©

**í˜„ì¬ êµ¬ì¡°**:
```
[System]
ë‹¹ì‹ ì€ ëŒ€í™” ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤...

[User]
#Person1#: ì•ˆë…•í•˜ì„¸ìš”.
#Person2#: ë°˜ê°‘ìŠµë‹ˆë‹¤.

ìœ„ ëŒ€í™”ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”.
```

**ë² ì´ìŠ¤ë¼ì¸ êµ¬ì¡°**:
```
[System]
ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

[User]
[Conversation]
í™”ìSD2000001: ì €ëŠ” ì—¬í–‰ ë‹¤ë‹ˆëŠ” ê²ƒì„ êµ‰ì¥íˆ ì¢‹ì•„í•˜ëŠ”ë°ìš”...
í™”ìSD2000002: ì € ì—¬í–‰ ë‹¤ë‹ˆëŠ” ê±° ë˜ê²Œ ì¢‹ì•„í•´ì„œ...

[Question]
ìœ„ í•´ì™¸ì—¬í–‰ ì£¼ì œì— ëŒ€í•œ ëŒ€í™”ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”.
```

### 2.2 êµ¬í˜„ ì½”ë“œ

**íŒŒì¼**: `scripts/llm_finetuning.py`

**ë³€ê²½ ìœ„ì¹˜**: `prepare_causal_lm_data()` í•¨ìˆ˜ ë‚´ prompt ìƒì„± ë¶€ë¶„

```python
# ê¸°ì¡´ ì½”ë“œ (ë‹¨ìˆœ í¬ë§·)
def format_dialogue_prompt(sample):
    # ë‹¨ìˆœíˆ dialogue í…ìŠ¤íŠ¸ë§Œ ì „ë‹¬
    return sample["dialogue"]

# ìƒˆ ì½”ë“œ (êµ¬ì¡°í™” í¬ë§·)
def format_dialogue_prompt(sample):
    # [Conversation] ì„¹ì…˜ ìƒì„±
    conversation_lines = ["[Conversation]"]

    # í™”ìë³„ ë°œí™” ì¶”ì¶œ
    dialogue = sample["dialogue"]
    turns = re.split(r'(#Person\d+#:)', dialogue)

    for i in range(1, len(turns), 2):
        speaker = turns[i].strip(':').strip()
        utterance = turns[i+1].strip()
        conversation_lines.append(f"{speaker}: {utterance}")

    conversation_text = "\n".join(conversation_lines)

    # [Question] ì„¹ì…˜ ìƒì„±
    # subject_keywordê°€ ìˆìœ¼ë©´ í™œìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ ë¬¸êµ¬
    subject = sample.get("subject_keyword", ["ëŒ€í™”"])[0]  # ì²« ë²ˆì§¸ í‚¤ì›Œë“œë§Œ ì‚¬ìš©
    question = f"[Question]\nìœ„ {subject} ì£¼ì œì— ëŒ€í•œ ëŒ€í™”ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”."

    return conversation_text + "\n\n" + question
```

**ì£¼ì˜ì‚¬í•­**:
- ë² ì´ìŠ¤ë¼ì¸ì€ `subject_keyword` í•„ë“œë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, ìš°ë¦¬ ë°ì´í„°ì—ëŠ” ì—†ì„ ìˆ˜ ìˆìŒ
- ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ "ëŒ€í™”"ë¡œ ëŒ€ì²´

---

### 2.3 Label Masking ë°©ì‹ ê°œì„  (Korean_DCS_2024 ë°©ì‹)

**í˜„ì¬ ë°©ì‹** (ë³µì¡í•˜ê³  ì‹¤íŒ¨ ê°€ëŠ¥):
```python
# 1. ì „ì²´ë¥¼ í•œë²ˆì— í† í¬ë‚˜ì´ì¦ˆ
full_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)
full_ids = tokenizer(full_text, ...)["input_ids"]

# 2. Assistant í—¤ë”ë¥¼ ë¬¸ìì—´ ê²€ìƒ‰ìœ¼ë¡œ ì°¾ê¸° (âŒ ì‹¤íŒ¨ ìœ„í—˜)
assistant_header_ids = tokenizer.encode(assistant_header, add_special_tokens=False)
for i in range(len(full_ids) - len(assistant_header_ids) + 1):
    if full_ids[i:i+len(assistant_header_ids)] == assistant_header_ids:
        prompt_length = i + len(assistant_header_ids)
        break

# 3. ì°¾ì§€ ëª»í•˜ë©´ fallback (Line 307-311)
if prompt_length == 0:
    labels = [-100] * len(full_ids)  # ì „ì²´ ë§ˆìŠ¤í‚¹
```

**ë¬¸ì œì **:
- âŒ Assistant í—¤ë”ë¥¼ ëª» ì°¾ì„ ìœ„í—˜ (truncation, í† í¬ë‚˜ì´ì € ë²„ì „ ì°¨ì´)
- âŒ ëª¨ë¸ë³„ë¡œ í—¤ë”ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
- âŒ ë””ë²„ê¹… ì–´ë ¤ì›€

---

**Korean_DCS_2024 ë°©ì‹** (ëª…í™•í•˜ê³  ì•ˆì „):
```python
# 1. Promptë§Œ ë”°ë¡œ í† í¬ë‚˜ì´ì¦ˆ (add_generation_prompt=True)
message_prompt = [
    {"role": "system", "content": system_prompt},
    {"role": "user", "content": chat}
]
source = tokenizer.apply_chat_template(
    message_prompt,
    add_generation_prompt=True,  # assistant í—¤ë”ê¹Œì§€ë§Œ
    return_tensors="pt"
)

# 2. Targetë§Œ ë”°ë¡œ í† í¬ë‚˜ì´ì¦ˆ
target = example["output"]
if target != "":
    target += tokenizer.eos_token
target_ids = tokenizer(
    target,
    return_attention_mask=False,
    add_special_tokens=False,
    return_tensors="pt"
)["input_ids"]

# 3. Concat + Label ë§ˆìŠ¤í‚¹ (ì •í™•í•¨!)
input_ids = torch.concat((source[0], target_ids[0]))
labels = torch.concat((
    torch.LongTensor([IGNORE_INDEX] * source[0].shape[0]),  # Prompt ì „ì²´ ë§ˆìŠ¤í‚¹
    target_ids[0]  # Responseë§Œ í•™ìŠµ
))
```

**ì¥ì **:
- âœ… ëª…í™•í•˜ê³  ì‹¤íŒ¨ê°€ ì—†ìŒ
- âœ… add_generation_prompt=Trueë¡œ ì •í™•í•œ ê²½ê³„ íŒŒì•…
- âœ… ê°„ë‹¨í•˜ê³  ì§ê´€ì  (ë””ë²„ê¹… ì‰¬ì›€)
- âœ… ëª¨ë¸ ë…ë¦½ì  (Llama/Qwen ëª¨ë‘ ë™ì‘)

---

**êµ¬í˜„ ê³„íš**:

**íŒŒì¼**: `scripts/llm_finetuning.py`
**í•¨ìˆ˜**: `prepare_causal_lm_data()` Line 268-320

**ë³€ê²½ ì „** (Lines 268-321):
```python
if template_type:  # Decoder-only (Llama, Qwen)
    full_text = templated["input"]
    full_ids = tokenizer(full_text, ...)["input_ids"]

    # Assistant í—¤ë” ê²€ìƒ‰...
    for i in range(len(full_ids) - len(assistant_header_ids) + 1):
        ...
```

**ë³€ê²½ í›„**:
```python
if template_type:  # Decoder-only (Llama, Qwen)
    # 1. Promptë§Œ í† í¬ë‚˜ì´ì¦ˆ (Korean_DCS_2024 ë°©ì‹)
    message_prompt = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"ë‹¤ìŒ ëŒ€í™”ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n---\n{dialogue}\n---"}
    ]
    source_ids = tokenizer.apply_chat_template(
        message_prompt,
        add_generation_prompt=True,  # assistant í—¤ë”ê¹Œì§€
        add_special_tokens=True,
        return_tensors="pt"
    )[0]  # [0]ìœ¼ë¡œ 1D í…ì„œ ì¶”ì¶œ

    # 2. Targetë§Œ í† í¬ë‚˜ì´ì¦ˆ
    target_text = summary + tokenizer.eos_token
    target_ids = tokenizer(
        target_text,
        add_special_tokens=False,
        truncation=True,
        max_length=max_target_length,
        return_tensors="pt"
    )["input_ids"][0]

    # 3. Concat + Label ë§ˆìŠ¤í‚¹
    input_ids = torch.concat((source_ids, target_ids)).tolist()
    labels = ([-100] * len(source_ids)) + target_ids.tolist()

    data_dicts.append({
        "input_ids": input_ids,
        "labels": labels
    })
```

**ì˜ˆìƒ íš¨ê³¼**:
- Prompt truncation ë¬¸ì œ ì™„ì „ í•´ê²°
- Label ê³„ì‚° ì •í™•ë„ 100% (í—¤ë” ê²€ìƒ‰ ì‹¤íŒ¨ 0%)
- ì½”ë“œ ê°€ë…ì„± ë° ìœ ì§€ë³´ìˆ˜ì„± ëŒ€í­ í–¥ìƒ

---

## âš¡ Phase 3: TRL SFTTrainer ì „í™˜ (2-3ì‹œê°„)

**ì†Œìš” ì‹œê°„**: 2-3ì‹œê°„
**ë¦¬ìŠ¤í¬**: ì¤‘ê°„
**ì˜ˆìƒ íš¨ê³¼**: í•™ìŠµ ì‹œê°„ 40-60% ë‹¨ì¶• (packing íš¨ê³¼)

### 3.1 TRL ì„¤ì¹˜

```bash
pip install trl==0.9.4
```

### 3.2 ì½”ë“œ ë³€ê²½

**íŒŒì¼**: `scripts/llm_finetuning.py`

**ë³€ê²½ ì „**:
```python
from transformers import Trainer, TrainingArguments

training_args = TrainingArguments(
    output_dir=output_dir,
    per_device_train_batch_size=training_config["per_device_train_batch_size"],
    ...
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=dev_dataset,
    data_collator=data_collator,
    callbacks=callbacks,
)
```

**ë³€ê²½ í›„**:
```python
from trl import SFTTrainer, SFTConfig

training_args = SFTConfig(
    # ê¸°ì¡´ TrainingArguments íŒŒë¼ë¯¸í„° ëª¨ë‘ ìœ ì§€
    output_dir=output_dir,
    per_device_train_batch_size=training_config["per_device_train_batch_size"],
    ...

    # TRL ì „ìš© íŒŒë¼ë¯¸í„° ì¶”ê°€
    max_seq_length=tokenizer_config.get("encoder_max_len", 1024) +
                   tokenizer_config.get("decoder_max_len", 200),
    packing=True,  # âœ… í•µì‹¬ ê¸°ëŠ¥!
    dataset_text_field="text",  # ë°ì´í„°ì…‹ì—ì„œ í…ìŠ¤íŠ¸ í•„ë“œëª… (ì¡°ì • í•„ìš”)
)

trainer = SFTTrainer(
    model=model,
    tokenizer=tokenizer,  # âœ… ëª…ì‹œì  ì „ë‹¬
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=dev_dataset,
    # data_collatorëŠ” SFTTrainerê°€ ìë™ ì²˜ë¦¬ (packing ì§€ì›)
    callbacks=callbacks,
)
```

### 3.3 ë°ì´í„°ì…‹ í¬ë§· ì¡°ì •

**ë¬¸ì œ**: SFTTrainerëŠ” `dataset_text_field`ë¡œ raw textë¥¼ ê¸°ëŒ€

**í•´ê²°ì±…**:

**Option A**: ë°ì´í„°ì…‹ í¬ë§· ë³€ê²½
```python
# ê¸°ì¡´: {"input_ids": [...], "labels": [...]}
# ë³€ê²½: {"text": "<full_prompt_with_response>"}

def prepare_sft_dataset(samples):
    texts = []
    for sample in samples:
        # Full conversation text ìƒì„±
        prompt = format_dialogue_prompt(sample)
        response = sample["summary"]

        # Chat template ì ìš©
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt},
            {"role": "assistant", "content": response}
        ]

        # Tokenizerì˜ chat template í™œìš©
        full_text = tokenizer.apply_chat_template(
            messages,
            tokenize=False,  # í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜
            add_generation_prompt=False
        )

        texts.append({"text": full_text})

    return Dataset.from_dict({"text": texts})
```

**Option B**: `formatting_func` ì‚¬ìš©
```python
def formatting_func(example):
    """SFTTrainerì— ì „ë‹¬í•  í¬ë§·íŒ… í•¨ìˆ˜"""
    prompt = format_dialogue_prompt(example)
    response = example["summary"]

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": prompt},
        {"role": "assistant", "content": response}
    ]

    return tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=False
    )

trainer = SFTTrainer(
    ...,
    formatting_func=formatting_func,  # âœ… ì´ ë°©ì‹ì´ ë” ê¹”ë”
)
```

---

## ğŸ“Š Phase 4: ê²€ì¦ ë° ì„±ëŠ¥ ë¹„êµ

### 4.1 A/B í…ŒìŠ¤íŠ¸ êµ¬ì„±

| ì„¤ì • | Phase 1 | Phase 2 | Phase 3 |
|------|---------|---------|---------|
| LR | 2e-5 | 2e-5 | 2e-5 |
| Scheduler | cosine | cosine | cosine |
| Weight Decay | 0.1 | 0.1 | 0.1 |
| Batch Size | 64 | 64 | 64 |
| Prompt | ë‹¨ìˆœ | **êµ¬ì¡°í™”** | êµ¬ì¡°í™” |
| Trainer | Trainer | Trainer | **SFTTrainer** |
| Packing | âŒ | âŒ | **âœ…** |

### 4.2 ì˜ˆìƒ ì„±ëŠ¥

| Metric | Phase 1 | Phase 2 | Phase 3 |
|--------|---------|---------|---------|
| ROUGE Sum | 60-70 | **70-80** | **75-85** |
| í•™ìŠµ ì‹œê°„/epoch | 60ë¶„ | 60ë¶„ | **25-35ë¶„** |
| Grad Norm Spike | <1.5 | <1.5 | <1.5 |
| ì™¸êµ­ì–´ í˜¼ì… | <3% | <1% | <1% |

---

## ğŸ›¡ï¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬

### Phase 1 ì‹¤í–‰ ë¦¬ìŠ¤í¬
- **ë¦¬ìŠ¤í¬**: ê±°ì˜ ì—†ìŒ (configë§Œ ë³€ê²½)
- **ë¡¤ë°±**: config íŒŒì¼ git revert
- **ê²€ì¦**: 1 epoch í•™ìŠµ í›„ grad_norm, loss ì¶”ì´ í™•ì¸

### Phase 2 ì‹¤í–‰ ë¦¬ìŠ¤í¬
- **ë¦¬ìŠ¤í¬**: ì¤‘ê°„ (prompt íŒŒì‹± ë²„ê·¸ ê°€ëŠ¥)
- **ë¡¤ë°±**: prompt ìƒì„± í•¨ìˆ˜ë§Œ ë˜ëŒë¦¬ê¸°
- **ê²€ì¦**: ì†Œìˆ˜ ìƒ˜í”Œë¡œ prompt ìƒì„± í…ŒìŠ¤íŠ¸

### Phase 3 ì‹¤í–‰ ë¦¬ìŠ¤í¬
- **ë¦¬ìŠ¤í¬**: ì¤‘ê°„ (Trainer â†’ SFTTrainer í˜¸í™˜ì„±)
- **ë¡¤ë°±**: ê¸°ì¡´ Trainer ì½”ë“œ ë³´ì¡´ (branch ìƒì„±)
- **ê²€ì¦**:
  - packing=Falseë¡œ ë¨¼ì € í…ŒìŠ¤íŠ¸
  - í•™ìŠµ loss ê³¡ì„  ë¹„êµ

---

## ğŸ“… ì‹¤í–‰ ìˆœì„œ

### ìš°ì„ ìˆœìœ„ 1: Phase 1 (ì¦‰ì‹œ)
```bash
# 1. Config ìˆ˜ì •
vim configs/finetune_config.yaml

# 2. 1 epoch í…ŒìŠ¤íŠ¸ í•™ìŠµ
python scripts/llm_finetuning.py --config configs/finetune_config.yaml

# 3. W&Bì—ì„œ grad_norm, loss í™•ì¸
# ì˜ˆìƒ: grad_norm < 1.5, loss ì•ˆì •ì  ê°ì†Œ
```

**íŒë‹¨ ê¸°ì¤€**:
- âœ… grad_norm < 1.5 ìœ ì§€ â†’ Phase 2 ì§„í–‰
- âŒ grad_norm ì—¬ì „íˆ spike â†’ LR ì¶”ê°€ ê°ì†Œ (1e-5)

---

### ìš°ì„ ìˆœìœ„ 2: Phase 2 (Phase 1 ì„±ê³µ ì‹œ)
```bash
# 1. Prompt ìƒì„± í•¨ìˆ˜ ìˆ˜ì •
vim scripts/llm_finetuning.py

# 2. ì†Œìˆ˜ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸
python -c "
from scripts.llm_finetuning import format_dialogue_prompt
# ìƒ˜í”Œë¡œ prompt ìƒì„± í™•ì¸
"

# 3. ì „ì²´ í•™ìŠµ
python scripts/llm_finetuning.py --config configs/finetune_config.yaml
```

**íŒë‹¨ ê¸°ì¤€**:
- âœ… ROUGE > 70 â†’ Phase 3 ì§„í–‰
- âŒ ROUGE < 70 â†’ Prompt ë””ë²„ê¹… ë˜ëŠ” Phase 1ë¡œ ì œì¶œ

---

### ìš°ì„ ìˆœìœ„ 3: Phase 3 (Phase 2 ì„±ê³µ ì‹œ)
```bash
# 1. TRL ì„¤ì¹˜
pip install trl==0.9.4

# 2. ì½”ë“œ ìˆ˜ì • (branch ìƒì„±)
git checkout -b feature/sft-trainer
vim scripts/llm_finetuning.py

# 3. Packing ë¹„í™œì„±í™” í…ŒìŠ¤íŠ¸
# packing=Falseë¡œ ë¨¼ì € í•™ìŠµí•˜ì—¬ í˜¸í™˜ì„± í™•ì¸

# 4. Packing í™œì„±í™”
# packing=Trueë¡œ í•™ìŠµ ì†ë„ ê°œì„  í™•ì¸
```

---

## ğŸ¯ ì„±ê³µ ê¸°ì¤€

### Phase 1
- [x] Grad_norm < 1.5 ì•ˆì • ìœ ì§€
- [x] Lossê°€ epochë§ˆë‹¤ ê°ì†Œ
- [x] ì™¸êµ­ì–´ í˜¼ì… < 3%

### Phase 2
- [x] ROUGE-1 > 35
- [x] ROUGE-L > 30
- [x] ROUGE Sum > 70

### Phase 3
- [x] í•™ìŠµ ì‹œê°„ 40% ì´ìƒ ë‹¨ì¶•
- [x] ROUGE ì„±ëŠ¥ ìœ ì§€ ë˜ëŠ” í–¥ìƒ
- [x] Packingìœ¼ë¡œ ì¸í•œ í’ˆì§ˆ ì €í•˜ ì—†ìŒ

---

## ğŸ“ ë¬¸ì„œí™” ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Phase 1 ì ìš© í›„ W&B ë§í¬ ê¸°ë¡
- [ ] Phase 2 ì ìš© í›„ ìƒ˜í”Œ ìƒì„± ê²°ê³¼ ë¹„êµ
- [ ] Phase 3 ì ìš© í›„ í•™ìŠµ ì‹œê°„ ì¸¡ì •
- [ ] ìµœì¢… ì„±ëŠ¥ ë¹„êµí‘œ ì—…ë°ì´íŠ¸
- [ ] CLAUDE.mdì— Critical Learnings ì¶”ê°€

---

## ğŸ”— ì°¸ê³  ìë£Œ

- Korean_DCS_2024 ë² ì´ìŠ¤ë¼ì¸: `/Competition/NLP/Korean_DCS_2024/`
- TRL ë¬¸ì„œ: https://huggingface.co/docs/trl
- í˜„ì¬ ì½”ë“œ: `/Competition/NLP/naturallanguageprocessingcompetition-nlp-1/dialogue-summarization/`
- W&B í”„ë¡œì íŠ¸: https://wandb.ai/bkan-ai/dialogue-summarization-finetuning

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-10-05 (ì‹¬ì¸µ ë¶„ì„ ì™„ë£Œ)
**ì‘ì„±ì**: Claude Code
**ìƒíƒœ**: Phase 1 ì™„ë£Œ, Phase 1.5 ì¤€ë¹„ ì¤‘
