{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🗨️ Dialogue Summarization - Inference Demo\n",
    "\n",
    "> 학습된 모델로 test 셋 예측 및 제출 파일 생성\n",
    "\n",
    "이 노트북은 학습된 모델을 사용하여 test 데이터에 대한 요약을 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# 프로젝트 루트를 Python path에 추가\n",
    "project_root = '/Competition/NLP/dialogue-summarization'\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "os.chdir(project_root)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모듈 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 우리가 만든 모듈들\n",
    "from src.data.preprocessor import Preprocess\n",
    "from src.data.dataset import DatasetForInference\n",
    "from src.models.model_loader import load_tokenizer_and_model\n",
    "from src.evaluation.metrics import clean_text\n",
    "\n",
    "print(\"✅ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 설정\n",
    "DATA_PATH = \"/Competition/NLP/naturallanguageprocessingcompetition-nlp-1/data\"\n",
    "CHECKPOINT_PATH = \"/Competition/NLP/dialogue-summarization/checkpoints/baseline_run/checkpoint-1750\"  # Best model\n",
    "OUTPUT_DIR = \"/Competition/NLP/dialogue-summarization/submissions\"\n",
    "\n",
    "# 생성 파라미터\n",
    "MAX_INPUT_LENGTH = 512\n",
    "MAX_OUTPUT_LENGTH = 100\n",
    "NUM_BEAMS = 4\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Special tokens\n",
    "SPECIAL_TOKENS = ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#']\n",
    "\n",
    "print(\"📋 Configuration:\")\n",
    "print(f\"  Data path: {DATA_PATH}\")\n",
    "print(f\"  Checkpoint: {CHECKPOINT_PATH}\")\n",
    "print(f\"  Output dir: {OUTPUT_DIR}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Num beams: {NUM_BEAMS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 디바이스 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"🖥️  Device: {device}\")\n",
    "\n",
    "if device == 'cuda':\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 & 토크나이저 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📥 Loading model and tokenizer...\")\n",
    "\n",
    "model, tokenizer = load_tokenizer_and_model(\n",
    "    model_name=\"digit82/kobart-summarization\",  # Base model name for config\n",
    "    special_tokens=SPECIAL_TOKENS,\n",
    "    device=device,\n",
    "    checkpoint_path=CHECKPOINT_PATH\n",
    ")\n",
    "\n",
    "model.eval()  # Evaluation mode\n",
    "\n",
    "print(f\"✅ Model loaded from: {CHECKPOINT_PATH}\")\n",
    "print(f\"   Vocab size: {len(tokenizer)}\")\n",
    "print(f\"   Model parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessor 초기화\n",
    "preprocessor = Preprocess(\n",
    "    bos_token=tokenizer.bos_token,\n",
    "    eos_token=tokenizer.eos_token\n",
    ")\n",
    "\n",
    "# Test 데이터 로드\n",
    "test_data = preprocessor.make_set_as_df(f\"{DATA_PATH}/test.csv\", is_train=False)\n",
    "\n",
    "print(f\"📊 Test data loaded: {len(test_data)} samples\")\n",
    "print(f\"\\n🔍 Sample:\")\n",
    "print(f\"   ID: {test_data.iloc[0]['fname']}\")\n",
    "print(f\"   Dialogue: {test_data.iloc[0]['dialogue'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 전처리\nencoder_input_test, _ = preprocessor.make_input(test_data, is_test=True)\n\n# 토크나이징\ntokenized_encoder_inputs = tokenizer(\n    encoder_input_test,\n    return_tensors=\"pt\",\n    padding=True,\n    truncation=True,\n    max_length=MAX_INPUT_LENGTH,\n    return_token_type_ids=False\n)\n\nprint(f\"✅ Tokenization completed\")\nprint(f\"   Input shape: {tokenized_encoder_inputs['input_ids'].shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Dataset & DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "test_dataset = DatasetForInference(\n    tokenized_encoder_inputs,\n    test_data['fname'].tolist(),  # test_id로 fname 리스트 전달\n    len(test_data)\n)\n\ntest_dataloader = DataLoader(\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)\n\nprint(f\"✅ DataLoader created\")\nprint(f\"   Total batches: {len(test_dataloader)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 추론 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🚀 Starting inference...\")\n",
    "\n",
    "summaries = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc=\"Generating summaries\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        \n",
    "        # Generate\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=MAX_OUTPUT_LENGTH,\n",
    "            num_beams=NUM_BEAMS,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=2\n",
    "        )\n",
    "        \n",
    "        # Decode\n",
    "        decoded = tokenizer.batch_decode(generated_ids, skip_special_tokens=False)\n",
    "        summaries.extend(decoded)\n",
    "\n",
    "print(f\"\\n✅ Inference completed!\")\n",
    "print(f\"   Generated {len(summaries)} summaries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 후처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 토큰 정리\nremove_tokens = ['<usr>', tokenizer.bos_token, tokenizer.eos_token, tokenizer.pad_token]\ncleaned_summaries = clean_text(summaries, remove_tokens)  # 리스트 전체를 한 번에 전달\n\nprint(\"✅ Post-processing completed\")\nprint(f\"\\n🔍 Sample outputs:\")\nfor i in range(min(3, len(cleaned_summaries))):\n    print(f\"\\n[Sample {i+1}]\")\n    print(f\"Original: {summaries[i][:80]}...\")\n    print(f\"Cleaned:  {cleaned_summaries[i][:80]}...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 디렉토리 생성\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# DataFrame 생성\n",
    "submission_df = pd.DataFrame({\n",
    "    'fname': test_data['fname'],\n",
    "    'summary': cleaned_summaries\n",
    "})\n",
    "\n",
    "# 파일명 생성 (타임스탬프 포함)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_filename = f\"submission_{timestamp}.csv\"\n",
    "output_path = os.path.join(OUTPUT_DIR, output_filename)\n",
    "\n",
    "# CSV 저장\n",
    "submission_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Submission file saved!\")\n",
    "print(f\"   Path: {output_path}\")\n",
    "print(f\"   Rows: {len(submission_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 미리보기\n",
    "print(\"📄 Submission file preview:\")\n",
    "print(submission_df.head(10))\n",
    "\n",
    "# 통계\n",
    "print(f\"\\n📊 Statistics:\")\n",
    "print(f\"   Total samples: {len(submission_df)}\")\n",
    "print(f\"   Average summary length: {submission_df['summary'].str.len().mean():.1f} chars\")\n",
    "print(f\"   Min summary length: {submission_df['summary'].str.len().min()} chars\")\n",
    "print(f\"   Max summary length: {submission_df['summary'].str.len().max()} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 샘플 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 몇 개 샘플 자세히 확인\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "sample_indices = random.sample(range(len(test_data)), min(3, len(test_data)))\n",
    "\n",
    "for idx in sample_indices:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Sample {idx + 1}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\n[Dialogue]\")\n",
    "    print(test_data.iloc[idx]['dialogue'][:300] + \"...\")\n",
    "    print(f\"\\n[Generated Summary]\")\n",
    "    print(submission_df.iloc[idx]['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 완료!\n",
    "\n",
    "### 다음 단계:\n",
    "1. **제출 파일 확인**: `submissions/` 폴더의 CSV 파일 확인\n",
    "2. **경진대회 제출**: 플랫폼에 CSV 파일 업로드\n",
    "3. **결과 확인**: 리더보드에서 점수 확인"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}