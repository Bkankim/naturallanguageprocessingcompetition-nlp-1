{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Hyperparameter Optimization\n",
    "\n",
    "Optunaë¥¼ ì‚¬ìš©í•œ ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”\n",
    "\n",
    "## ëª©í‘œ\n",
    "1. Optuna ë² ì´ì§€ì•ˆ ìµœì í™” ì„¤ì •\n",
    "2. WandB Sweep í†µí•©\n",
    "3. 20+ trials ì‹¤í–‰\n",
    "4. ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ë°œê²¬ ë° ì €ì¥\n",
    "5. ìµœì  ì„¤ì •ìœ¼ë¡œ ì¬í•™ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Base Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CONFIG = {\n",
    "    # Experiment\n",
    "    \"exp_name\": \"kobart-optuna\",\n",
    "    \"seed\": 42,\n",
    "    \"n_trials\": 20,\n",
    "    \n",
    "    # Model\n",
    "    \"model_name\": \"gogamza/kobart-base-v2\",\n",
    "    \"max_input_length\": 512,\n",
    "    \"max_target_length\": 128,\n",
    "    \n",
    "    # Fixed training params\n",
    "    \"fp16\": True,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"eval_steps\": 500,\n",
    "    \"save_steps\": 500,\n",
    "    \"logging_steps\": 100,\n",
    "    \n",
    "    # Paths\n",
    "    \"data_dir\": \"../data/processed\",\n",
    "    \"config_dir\": \"../configs\",\n",
    "    \"checkpoint_dir\": \"../checkpoints/optuna\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Custom utilities\n",
    "from utils import (\n",
    "    set_seed,\n",
    "    compute_rouge,\n",
    "    auto_git_backup\n",
    ")\n",
    "\n",
    "# Set seed\n",
    "set_seed(BASE_CONFIG[\"seed\"])\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(BASE_CONFIG[\"checkpoint_dir\"], exist_ok=True)\n",
    "\n",
    "# Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ğŸ–¥ï¸ Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "train_df = pd.read_csv(os.path.join(BASE_CONFIG[\"data_dir\"], \"train_processed.csv\"))\n",
    "train_df = train_df[['fname', 'dialogue_clean', 'summary_clean']].rename(\n",
    "    columns={'dialogue_clean': 'dialogue', 'summary_clean': 'summary'}\n",
    ")\n",
    "\n",
    "# Train/validation split\n",
    "train_data, val_data = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.1,\n",
    "    random_state=BASE_CONFIG[\"seed\"]\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“Š Train: {len(train_data):,}, Val: {len(val_data):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer (will be reused across trials)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_CONFIG[\"model_name\"])\n",
    "\n",
    "# Load special tokens\n",
    "special_tokens_path = os.path.join(BASE_CONFIG[\"config_dir\"], \"special_tokens.json\")\n",
    "if os.path.exists(special_tokens_path):\n",
    "    with open(special_tokens_path, 'r', encoding='utf-8') as f:\n",
    "        special_tokens_config = json.load(f)\n",
    "    tokenizer.add_special_tokens({\n",
    "        'additional_special_tokens': special_tokens_config['additional_special_tokens']\n",
    "    })\n",
    "\n",
    "print(f\"âœ… Tokenizer loaded with {len(tokenizer)} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess datasets once\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples['dialogue'],\n",
    "        max_length=BASE_CONFIG[\"max_input_length\"],\n",
    "        truncation=True,\n",
    "        padding=False\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples['summary'],\n",
    "        max_length=BASE_CONFIG[\"max_target_length\"],\n",
    "        truncation=True,\n",
    "        padding=False\n",
    "    )\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data.reset_index(drop=True))\n",
    "val_dataset = Dataset.from_pandas(val_data.reset_index(drop=True))\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=['dialogue', 'summary']\n",
    ")\n",
    "val_dataset = val_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=['dialogue', 'summary']\n",
    ")\n",
    "\n",
    "print(\"âœ… Datasets preprocessed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¬ Optuna Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Optuna objective function.\"\"\"\n",
    "    \n",
    "    # Suggest hyperparameters\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-4, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [4, 8, 16])\n",
    "    gradient_accumulation_steps = trial.suggest_categorical(\"gradient_accumulation_steps\", [1, 2, 4])\n",
    "    warmup_ratio = trial.suggest_float(\"warmup_ratio\", 0.0, 0.2)\n",
    "    num_train_epochs = trial.suggest_int(\"num_train_epochs\", 3, 10)\n",
    "    num_beams = trial.suggest_int(\"num_beams\", 3, 6)\n",
    "    length_penalty = trial.suggest_float(\"length_penalty\", 0.5, 2.0)\n",
    "    \n",
    "    # Load model\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(BASE_CONFIG[\"model_name\"])\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Data collator\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=os.path.join(BASE_CONFIG[\"checkpoint_dir\"], f\"trial_{trial.number}\"),\n",
    "        \n",
    "        # Hyperparameters from trial\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size * 2,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        warmup_ratio=warmup_ratio,\n",
    "        \n",
    "        # Fixed params\n",
    "        fp16=BASE_CONFIG[\"fp16\"],\n",
    "        gradient_checkpointing=BASE_CONFIG[\"gradient_checkpointing\"],\n",
    "        \n",
    "        # Evaluation\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=BASE_CONFIG[\"eval_steps\"],\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=BASE_CONFIG[\"save_steps\"],\n",
    "        logging_steps=BASE_CONFIG[\"logging_steps\"],\n",
    "        \n",
    "        # Prediction\n",
    "        predict_with_generate=True,\n",
    "        generation_max_length=BASE_CONFIG[\"max_target_length\"],\n",
    "        generation_num_beams=num_beams,\n",
    "        \n",
    "        # Saving\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_rouge_sum\",\n",
    "        greater_is_better=True,\n",
    "        \n",
    "        # WandB\n",
    "        report_to=\"wandb\",\n",
    "        run_name=f\"{BASE_CONFIG['exp_name']}-trial{trial.number}\",\n",
    "        \n",
    "        # Misc\n",
    "        seed=BASE_CONFIG[\"seed\"],\n",
    "    )\n",
    "    \n",
    "    # Compute metrics\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        result = compute_rouge(\n",
    "            predictions=decoded_preds,\n",
    "            references=decoded_labels,\n",
    "            use_korean_tokenizer=True\n",
    "        )\n",
    "        return result\n",
    "    \n",
    "    # Trainer\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    trainer.train()\n",
    "    \n",
    "    # Evaluate\n",
    "    eval_results = trainer.evaluate()\n",
    "    rouge_sum = eval_results['eval_rouge_sum']\n",
    "    \n",
    "    # Clean up to save memory\n",
    "    del model\n",
    "    del trainer\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return rouge_sum\n",
    "\n",
    "print(\"âœ… Objective function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Run Optuna Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Optuna study\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=BASE_CONFIG[\"exp_name\"],\n",
    "    sampler=optuna.samplers.TPESampler(seed=BASE_CONFIG[\"seed\"])\n",
    ")\n",
    "\n",
    "print(f\"ğŸ”¬ Starting Optuna study with {BASE_CONFIG['n_trials']} trials...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimization\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=BASE_CONFIG[\"n_trials\"],\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Optimization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best trial\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(\"\\nğŸ† Best Trial:\")\n",
    "print(f\"  Value (ROUGE sum): {best_trial.value:.4f}\")\n",
    "print(f\"  Params:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Optimization history\n",
    "trial_nums = [trial.number for trial in study.trials]\n",
    "values = [trial.value for trial in study.trials]\n",
    "axes[0].plot(trial_nums, values, 'bo-')\n",
    "axes[0].axhline(best_trial.value, color='r', linestyle='--', label='Best')\n",
    "axes[0].set_xlabel('Trial')\n",
    "axes[0].set_ylabel('ROUGE Sum')\n",
    "axes[0].set_title('Optimization History')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Parameter importance\n",
    "importance = optuna.importance.get_param_importances(study)\n",
    "params = list(importance.keys())\n",
    "importances = list(importance.values())\n",
    "axes[1].barh(params, importances)\n",
    "axes[1].set_xlabel('Importance')\n",
    "axes[1].set_title('Parameter Importance')\n",
    "axes[1].grid(True, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Save Best Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create best config\n",
    "best_config = {\n",
    "    **BASE_CONFIG,\n",
    "    **best_trial.params,\n",
    "    \"best_rouge_sum\": best_trial.value,\n",
    "    \"trial_number\": best_trial.number\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "best_config_path = os.path.join(BASE_CONFIG[\"config_dir\"], \"best_config_stage3.json\")\n",
    "with open(best_config_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(best_config, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ… Best config saved to {best_config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Summary\n",
    "\n",
    "**ì™„ë£Œëœ ì‘ì—…**:\n",
    "- âœ… Optuna ë² ì´ì§€ì•ˆ ìµœì í™” ì„¤ì •\n",
    "- âœ… 20+ trials ì‹¤í–‰\n",
    "- âœ… ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ë°œê²¬\n",
    "- âœ… best_config_stage3.json ì €ì¥\n",
    "- âœ… ìµœì í™” ê²°ê³¼ ì‹œê°í™”\n",
    "\n",
    "**ë‹¤ìŒ ë‹¨ê³„**: \n",
    "- best_configë¡œ ì „ì²´ ë°ì´í„°ì…‹ ì¬í•™ìŠµ\n",
    "- Stage 4 - Advanced Models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
