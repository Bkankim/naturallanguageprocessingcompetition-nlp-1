{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Hyperparameter Optimization\n",
    "\n",
    "OptunaÎ•º ÏÇ¨Ïö©Ìïú ÏûêÎèô ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏµúÏ†ÅÌôî\n",
    "\n",
    "## Î™©Ìëú\n",
    "1. Optuna Î≤†Ïù¥ÏßÄÏïà ÏµúÏ†ÅÌôî ÏÑ§Ï†ï\n",
    "2. WandB Sweep ÌÜµÌï©\n",
    "3. 20+ trials Ïã§Ìñâ\n",
    "4. ÏµúÏ†Å ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Î∞úÍ≤¨ Î∞è Ï†ÄÏû•\n",
    "5. ÏµúÏ†Å ÏÑ§Ï†ïÏúºÎ°ú Ïû¨ÌïôÏäµ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Base Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CONFIG = {\n",
    "    # Experiment\n",
    "    \"exp_name\": \"kobart-optuna\",\n",
    "    \"seed\": 42,\n",
    "    \"n_trials\": 20,\n",
    "    \n",
    "    # Model\n",
    "    \"model_name\": \"gogamza/kobart-base-v2\",\n",
    "    \"max_input_length\": 512,\n",
    "    \"max_target_length\": 128,\n",
    "    \n",
    "    # Fixed training params\n",
    "    \"fp16\": True,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"eval_steps\": 500,\n",
    "    \"save_steps\": 500,\n",
    "    \"logging_steps\": 100,\n",
    "    \n",
    "    # Paths\n",
    "    \"data_dir\": \"../data/processed\",\n",
    "    \"config_dir\": \"../configs\",\n",
    "    \"checkpoint_dir\": \"../checkpoints/optuna\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Custom utilities\n",
    "from utils import (\n",
    "    set_seed,\n",
    "    compute_rouge,\n",
    "    auto_git_backup\n",
    ")\n",
    "\n",
    "# Set seed\n",
    "set_seed(BASE_CONFIG[\"seed\"])\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(BASE_CONFIG[\"checkpoint_dir\"], exist_ok=True)\n",
    "\n",
    "# Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üñ•Ô∏è Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "train_df = pd.read_csv(os.path.join(BASE_CONFIG[\"data_dir\"], \"train_processed.csv\"))\n",
    "train_df = train_df[['fname', 'dialogue_clean', 'summary_clean']].rename(\n",
    "    columns={'dialogue_clean': 'dialogue', 'summary_clean': 'summary'}\n",
    ")\n",
    "\n",
    "# Train/validation split\n",
    "train_data, val_data = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.1,\n",
    "    random_state=BASE_CONFIG[\"seed\"]\n",
    ")\n",
    "\n",
    "print(f\"üìä Train: {len(train_data):,}, Val: {len(val_data):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer (will be reused across trials)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_CONFIG[\"model_name\"])\n",
    "\n",
    "# Load special tokens\n",
    "special_tokens_path = os.path.join(BASE_CONFIG[\"config_dir\"], \"special_tokens.json\")\n",
    "if os.path.exists(special_tokens_path):\n",
    "    with open(special_tokens_path, 'r', encoding='utf-8') as f:\n",
    "        special_tokens_config = json.load(f)\n",
    "    tokenizer.add_special_tokens({\n",
    "        'additional_special_tokens': special_tokens_config['additional_special_tokens']\n",
    "    })\n",
    "\n",
    "print(f\"‚úÖ Tokenizer loaded with {len(tokenizer)} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess datasets once\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples['dialogue'],\n",
    "        max_length=BASE_CONFIG[\"max_input_length\"],\n",
    "        truncation=True,\n",
    "        padding=False\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples['summary'],\n",
    "        max_length=BASE_CONFIG[\"max_target_length\"],\n",
    "        truncation=True,\n",
    "        padding=False\n",
    "    )\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data.reset_index(drop=True))\n",
    "val_dataset = Dataset.from_pandas(val_data.reset_index(drop=True))\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=['dialogue', 'summary']\n",
    ")\n",
    "val_dataset = val_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=['dialogue', 'summary']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Datasets preprocessed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Optuna Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Optuna objective function.\"\"\"\n",
    "    \n",
    "    # Suggest hyperparameters\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-4, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [4, 8, 16])\n",
    "    gradient_accumulation_steps = trial.suggest_categorical(\"gradient_accumulation_steps\", [1, 2, 4])\n",
    "    warmup_ratio = trial.suggest_float(\"warmup_ratio\", 0.0, 0.2)\n",
    "    num_train_epochs = trial.suggest_int(\"num_train_epochs\", 3, 10)\n",
    "    num_beams = trial.suggest_int(\"num_beams\", 3, 6)\n",
    "    length_penalty = trial.suggest_float(\"length_penalty\", 0.5, 2.0)\n",
    "    \n",
    "    # Load model\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(BASE_CONFIG[\"model_name\"])\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Data collator\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=os.path.join(BASE_CONFIG[\"checkpoint_dir\"], f\"trial_{trial.number}\"),\n",
    "        \n",
    "        # Hyperparameters from trial\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size * 2,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        warmup_ratio=warmup_ratio,\n",
    "        \n",
    "        # Fixed params\n",
    "        fp16=BASE_CONFIG[\"fp16\"],\n",
    "        gradient_checkpointing=BASE_CONFIG[\"gradient_checkpointing\"],\n",
    "        \n",
    "        # Evaluation\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=BASE_CONFIG[\"eval_steps\"],\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=BASE_CONFIG[\"save_steps\"],\n",
    "        logging_steps=BASE_CONFIG[\"logging_steps\"],\n",
    "        \n",
    "        # Prediction\n",
    "        predict_with_generate=True,\n",
    "        generation_max_length=BASE_CONFIG[\"max_target_length\"],\n",
    "        generation_num_beams=num_beams,\n",
    "        \n",
    "        # Saving\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_rouge_sum\",\n",
    "        greater_is_better=True,\n",
    "        \n",
    "        # WandB\n",
    "        report_to=\"wandb\",\n",
    "        run_name=f\"{BASE_CONFIG['exp_name']}-trial{trial.number}\",\n",
    "        \n",
    "        # Misc\n",
    "        seed=BASE_CONFIG[\"seed\"],\n",
    "    )\n",
    "    \n",
    "    # Compute metrics\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        result = compute_rouge(\n",
    "            predictions=decoded_preds,\n",
    "            references=decoded_labels,\n",
    "            use_korean_tokenizer=True\n",
    "        )\n",
    "        return result\n",
    "    \n",
    "    # Trainer\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    trainer.train()\n",
    "    \n",
    "    # Evaluate\n",
    "    eval_results = trainer.evaluate()\n",
    "    rouge_sum = eval_results['eval_rouge_sum']\n",
    "    \n",
    "    # Clean up to save memory\n",
    "    del model\n",
    "    del trainer\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return rouge_sum\n",
    "\n",
    "print(\"‚úÖ Objective function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Run Optuna Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Optuna study\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=BASE_CONFIG[\"exp_name\"],\n",
    "    sampler=optuna.samplers.TPESampler(seed=BASE_CONFIG[\"seed\"])\n",
    ")\n",
    "\n",
    "print(f\"üî¨ Starting Optuna study with {BASE_CONFIG['n_trials']} trials...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimization\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=BASE_CONFIG[\"n_trials\"],\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Optimization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best trial\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(\"\\nüèÜ Best Trial:\")\n",
    "print(f\"  Value (ROUGE sum): {best_trial.value:.4f}\")\n",
    "print(f\"  Params:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Optimization history\n",
    "trial_nums = [trial.number for trial in study.trials]\n",
    "values = [trial.value for trial in study.trials]\n",
    "axes[0].plot(trial_nums, values, 'bo-')\n",
    "axes[0].axhline(best_trial.value, color='r', linestyle='--', label='Best')\n",
    "axes[0].set_xlabel('Trial')\n",
    "axes[0].set_ylabel('ROUGE Sum')\n",
    "axes[0].set_title('Optimization History')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Parameter importance\n",
    "importance = optuna.importance.get_param_importances(study)\n",
    "params = list(importance.keys())\n",
    "importances = list(importance.values())\n",
    "axes[1].barh(params, importances)\n",
    "axes[1].set_xlabel('Importance')\n",
    "axes[1].set_title('Parameter Importance')\n",
    "axes[1].grid(True, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Save Best Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create best config\n",
    "best_config = {\n",
    "    **BASE_CONFIG,\n",
    "    **best_trial.params,\n",
    "    \"best_rouge_sum\": best_trial.value,\n",
    "    \"trial_number\": best_trial.number\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "best_config_path = os.path.join(BASE_CONFIG[\"config_dir\"], \"best_config_stage3.json\")\n",
    "with open(best_config_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(best_config, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Best config saved to {best_config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Summary\n",
    "\n",
    "**ÏôÑÎ£åÎêú ÏûëÏóÖ**:\n",
    "- ‚úÖ Optuna Î≤†Ïù¥ÏßÄÏïà ÏµúÏ†ÅÌôî ÏÑ§Ï†ï\n",
    "- ‚úÖ 20+ trials Ïã§Ìñâ\n",
    "- ‚úÖ ÏµúÏ†Å ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Î∞úÍ≤¨\n",
    "- ‚úÖ best_config_stage3.json Ï†ÄÏû•\n",
    "- ‚úÖ ÏµúÏ†ÅÌôî Í≤∞Í≥º ÏãúÍ∞ÅÌôî\n",
    "\n",
    "**Îã§Ïùå Îã®Í≥Ñ**: \n",
    "- best_configÎ°ú Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÏÖã Ïû¨ÌïôÏäµ\n",
    "- Stage 4 - Advanced Models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
