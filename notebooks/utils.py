"""
ê²½ì§„ëŒ€íšŒ íŒŒì´í”„ë¼ì¸ì„ ìœ„í•œ í•µì‹¬ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤.

ì´ ëª¨ë“ˆì€ WandB í†µí•©, ROUGE í‰ê°€, Git ìë™ ë°±ì—…, ì¬í˜„ì„± ë³´ì¥, í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë“±
ì „ì²´ ë…¸íŠ¸ë¶ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import random
import re
import subprocess
from datetime import datetime
from typing import Any, Dict, List, Optional, Union

import numpy as np
import torch
import transformers
import wandb
from konlpy.tag import Okt
from rouge_score import rouge_scorer


# WandB ì„¤ì • ë° ì´ˆê¸°í™”
def setup_wandb(
    project_name: str,
    config_dict: Dict[str, Any],
    run_name: Optional[str] = None,
    tags: Optional[List[str]] = None
) -> wandb.run:
    """WandB ì‹¤í—˜ ì¶”ì ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

    Args:
        project_name: WandB í”„ë¡œì íŠ¸ ì´ë¦„
        config_dict: ì‹¤í—˜ ì„¤ì • (í•˜ì´í¼íŒŒë¼ë¯¸í„°, ëª¨ë¸ ì •ë³´ ë“±)
        run_name: ì‹¤í—˜ run ì´ë¦„ (Noneì´ë©´ ìë™ ìƒì„±)
        tags: ì‹¤í—˜ íƒœê·¸ ë¦¬ìŠ¤íŠ¸

    Returns:
        ì´ˆê¸°í™”ëœ WandB run ê°ì²´

    Example:
        >>> config = {"model": "kobart", "lr": 5e-5, "batch_size": 16}
        >>> run = setup_wandb("dialogue-summarization", config)
    """
    # Run name ìë™ ìƒì„±
    if run_name is None:
        model_name = config_dict.get("model_name", "model")
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        run_name = f"{model_name}-{timestamp}"

    # WandB ì´ˆê¸°í™”
    run = wandb.init(
        project=project_name,
        name=run_name,
        config=config_dict,
        tags=tags or [],
        reinit=True  # ë…¸íŠ¸ë¶ì—ì„œ ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡
    )

    print(f"âœ… WandB initialized: {run_name}")
    print(f"ğŸ“Š Dashboard: {run.url}")

    return run


# ROUGE ì ìˆ˜ ê³„ì‚°
def compute_rouge(
    predictions: List[str],
    references: Union[List[str], List[List[str]]],
    use_korean_tokenizer: bool = True
) -> Dict[str, float]:
    """ROUGE ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

    í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸°(Okt)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ ROUGE ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    ê²½ì§„ëŒ€íšŒ í‰ê°€ ë°©ì‹ì— ë”°ë¼ 3ê°œ reference ì¤‘ ìµœëŒ€ê°’ì„ ì„ íƒí•©ë‹ˆë‹¤.

    Args:
        predictions: ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        references: ì •ë‹µ ìš”ì•½ ë¦¬ìŠ¤íŠ¸ (ê° ì˜ˆì¸¡ë‹¹ 1ê°œ ë˜ëŠ” 3ê°œ)
        use_korean_tokenizer: í•œêµ­ì–´ í† í¬ë‚˜ì´ì € ì‚¬ìš© ì—¬ë¶€

    Returns:
        ROUGE-1, ROUGE-2, ROUGE-L F1 ì ìˆ˜ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬

    Example:
        >>> preds = ["ìš”ì•½ë¬¸ 1", "ìš”ì•½ë¬¸ 2"]
        >>> refs = [["ì •ë‹µ1-1", "ì •ë‹µ1-2", "ì •ë‹µ1-3"], ["ì •ë‹µ2-1", "ì •ë‹µ2-2", "ì •ë‹µ2-3"]]
        >>> scores = compute_rouge(preds, refs)
        >>> print(scores["rouge1"])  # 71.5
    """
    # í•œêµ­ì–´ í† í¬ë‚˜ì´ì € ì´ˆê¸°í™”
    if use_korean_tokenizer:
        okt = Okt()
        def tokenizer(text: str) -> List[str]:
            return okt.morphs(text)
    else:
        tokenizer = None

    # ROUGE scorer ìƒì„±
    scorer = rouge_scorer.RougeScorer(
        ['rouge1', 'rouge2', 'rougeL'],
        use_stemmer=False,
        tokenizer=tokenizer
    )

    # ì ìˆ˜ ê³„ì‚°
    rouge1_scores = []
    rouge2_scores = []
    rougeL_scores = []

    for pred, ref in zip(predictions, references):
        # Referenceê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (3ê°œ reference)
        if isinstance(ref, list):
            # ê° referenceì— ëŒ€í•´ ì ìˆ˜ ê³„ì‚° í›„ ìµœëŒ€ê°’ ì„ íƒ
            scores_per_ref = [scorer.score(r, pred) for r in ref]
            max_rouge1 = max(s['rouge1'].fmeasure for s in scores_per_ref)
            max_rouge2 = max(s['rouge2'].fmeasure for s in scores_per_ref)
            max_rougeL = max(s['rougeL'].fmeasure for s in scores_per_ref)

            rouge1_scores.append(max_rouge1)
            rouge2_scores.append(max_rouge2)
            rougeL_scores.append(max_rougeL)
        else:
            # Referenceê°€ ë‹¨ì¼ ë¬¸ìì—´ì¸ ê²½ìš°
            scores = scorer.score(ref, pred)
            rouge1_scores.append(scores['rouge1'].fmeasure)
            rouge2_scores.append(scores['rouge2'].fmeasure)
            rougeL_scores.append(scores['rougeL'].fmeasure)

    # í‰ê·  ì ìˆ˜ ê³„ì‚°
    result = {
        "rouge1": np.mean(rouge1_scores) * 100,  # 0-100 ìŠ¤ì¼€ì¼
        "rouge2": np.mean(rouge2_scores) * 100,
        "rougeL": np.mean(rougeL_scores) * 100,
    }
    result["rouge_sum"] = result["rouge1"] + result["rouge2"] + result["rougeL"]

    return result


# Git ìë™ ë°±ì—…
def auto_git_backup(
    exp_num: str,
    model_name: str,
    rouge_score: float,
    config: Dict[str, Any],
    message_prefix: str = "Exp"
) -> bool:
    """ì‹¤í—˜ ê²°ê³¼ë¥¼ Gitì— ìë™ìœ¼ë¡œ ë°±ì—…í•©ë‹ˆë‹¤.

    ì‹¤í—˜ ë²ˆí˜¸, ëª¨ë¸ ì´ë¦„, ROUGE ì ìˆ˜, ì„¤ì •ì„ í¬í•¨í•œ ì»¤ë°‹ ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ê³ 
    ìë™ìœ¼ë¡œ ì»¤ë°‹ ë° í‘¸ì‹œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    Args:
        exp_num: ì‹¤í—˜ ë²ˆí˜¸ (ì˜ˆ: "001", "002")
        model_name: ëª¨ë¸ ì´ë¦„ (ì˜ˆ: "KoBART-base")
        rouge_score: ROUGE í•©ê³„ ì ìˆ˜
        config: ì‹¤í—˜ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        message_prefix: ì»¤ë°‹ ë©”ì‹œì§€ prefix

    Returns:
        ë°±ì—… ì„±ê³µ ì—¬ë¶€

    Example:
        >>> config = {"lr": 5e-5, "batch_size": 16, "epochs": 10}
        >>> success = auto_git_backup("001", "KoBART", 72.5, config)
    """
    try:
        # ì»¤ë°‹ ë©”ì‹œì§€ ìƒì„±
        lr = config.get("learning_rate", config.get("lr", "N/A"))
        bs = config.get("batch_size", config.get("bs", "N/A"))
        epochs = config.get("num_train_epochs", config.get("epochs", "N/A"))

        commit_message = f"""{message_prefix} #{exp_num}: {model_name} | ROUGE: {rouge_score:.1f} | lr={lr}, bs={bs}, epochs={epochs}

ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>"""

        # Git ì‘ì—… ë””ë ‰í† ë¦¬ë¡œ ì´ë™ (CLAUDE.mdì— ëª…ì‹œëœ ê·œì¹™ ì¤€ìˆ˜)
        git_dir = "/Competition/NLP/naturallanguageprocessingcompetition-nlp-1"

        # Git add
        subprocess.run(
            ["git", "add", "."],
            cwd=git_dir,
            check=True,
            capture_output=True
        )

        # Git commit
        subprocess.run(
            ["git", "commit", "-m", commit_message],
            cwd=git_dir,
            check=True,
            capture_output=True
        )

        # Git push (3íšŒ ì¬ì‹œë„)
        for attempt in range(3):
            try:
                subprocess.run(
                    ["git", "push", "origin", "main"],
                    cwd=git_dir,
                    check=True,
                    capture_output=True,
                    timeout=120
                )
                print(f"âœ… Git backup successful: Exp #{exp_num}")
                return True
            except subprocess.TimeoutExpired:
                print(f"âš ï¸ Push timeout (attempt {attempt + 1}/3)")
                if attempt == 2:
                    print("âŒ Git push failed after 3 attempts")
                    return False
            except subprocess.CalledProcessError as e:
                print(f"âŒ Git push failed: {e.stderr.decode()}")
                return False

        return False

    except subprocess.CalledProcessError as e:
        print(f"âŒ Git backup failed: {e.stderr.decode()}")
        return False
    except Exception as e:
        print(f"âŒ Git backup error: {str(e)}")
        return False


# ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ê³ ì •
def set_seed(seed: int = 42) -> None:
    """ì¬í˜„ì„±ì„ ìœ„í•´ ëª¨ë“  ë‚œìˆ˜ ìƒì„±ê¸°ì˜ ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.

    Python random, NumPy, PyTorch, Transformersì˜ ì‹œë“œë¥¼ ëª¨ë‘ ì„¤ì •í•˜ì—¬
    ì‹¤í—˜ ê²°ê³¼ë¥¼ ì¬í˜„ ê°€ëŠ¥í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.

    Args:
        seed: ì„¤ì •í•  ì‹œë“œ ê°’ (ê¸°ë³¸ê°’: 42)

    Example:
        >>> set_seed(42)
        >>> # ì´ì œ ëª¨ë“  ë‚œìˆ˜ ìƒì„±ì´ ì¬í˜„ ê°€ëŠ¥í•©ë‹ˆë‹¤
    """
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)

    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        # CUDA ì—°ì‚°ì˜ ì¬í˜„ì„± ë³´ì¥ (ì„±ëŠ¥ trade-off ìˆìŒ)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

    transformers.set_seed(seed)

    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    os.environ['PYTHONHASHSEED'] = str(seed)

    print(f"âœ… Seed set to {seed} for reproducibility")


# ëŒ€í™” í…ìŠ¤íŠ¸ ì •ì œ
def clean_dialogue(text: str) -> str:
    """ëŒ€í™” í…ìŠ¤íŠ¸ì˜ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ê³  ì •ì œí•©ë‹ˆë‹¤.

    ê²½ì§„ëŒ€íšŒ ë°ì´í„°ì— í¬í•¨ëœ ë‹¤ì–‘í•œ ë…¸ì´ì¦ˆ íŒ¨í„´ì„ ì œê±°í•©ë‹ˆë‹¤:
    - Escaped newlines (\\\\n â†’ \\n)
    - HTML tags (<br> â†’ \\n)
    - ì—°ì†ëœ ê³µë°± â†’ ë‹¨ì¼ ê³µë°±
    - Informal tokens (ã…‹ã…‹, ã…‡ã…‡ ë“±) ì •ë¦¬

    Args:
        text: ì •ì œí•  ëŒ€í™” í…ìŠ¤íŠ¸

    Returns:
        ì •ì œëœ í…ìŠ¤íŠ¸

    Example:
        >>> raw = "#Person1#: ì•ˆë…•í•˜ì„¸ìš”\\\\n#Person2#: ë„¤<br>ë°˜ê°‘ìŠµë‹ˆë‹¤ã…‹ã…‹"
        >>> clean = clean_dialogue(raw)
        >>> print(clean)
        #Person1#: ì•ˆë…•í•˜ì„¸ìš”
        #Person2#: ë„¤ ë°˜ê°‘ìŠµë‹ˆë‹¤
    """
    # Escaped newlines ì²˜ë¦¬
    text = text.replace('\\\\n', '\n')

    # HTML tags ì²˜ë¦¬
    text = text.replace('<br>', '\n')
    text = text.replace('<br/>', '\n')
    text = text.replace('<br />', '\n')

    # Informal tokens ì •ë¦¬ (ì„ íƒì  - ê²½ìš°ì— ë”°ë¼ ì£¼ì„ ì²˜ë¦¬)
    # text = re.sub(r'ã…‹+', '', text)  # ã…‹ã…‹ã…‹ ì œê±°
    # text = re.sub(r'ã…+', '', text)  # ã…ã…ã… ì œê±°
    # text = re.sub(r'ã…‡ã…‡', '', text)  # ã…‡ã…‡ ì œê±°

    # ì—°ì†ëœ ê³µë°± ì œê±°
    text = re.sub(r' +', ' ', text)

    # ì—°ì†ëœ ì¤„ë°”ê¿ˆ ì œê±° (ìµœëŒ€ 2ê°œê¹Œì§€ ìœ ì§€)
    text = re.sub(r'\n{3,}', '\n\n', text)

    # ì•ë’¤ ê³µë°± ì œê±°
    text = text.strip()

    return text


# ì¶”ê°€ ìœ í‹¸ë¦¬í‹°: íŠ¹ìˆ˜ í† í° ì¶”ì¶œ
def extract_special_tokens(text: str) -> List[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ìˆ˜ í† í°ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

    #Person1#, #PhoneNumber# ê°™ì€ íŠ¹ìˆ˜ í† í°ì„ ì‹ë³„í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    Tokenizerì— ì¶”ê°€í•  special tokensì„ ì¤€ë¹„í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.

    Args:
        text: ë¶„ì„í•  í…ìŠ¤íŠ¸

    Returns:
        ë°œê²¬ëœ íŠ¹ìˆ˜ í† í° ë¦¬ìŠ¤íŠ¸

    Example:
        >>> text = "#Person1#: ì œ ë²ˆí˜¸ëŠ” #PhoneNumber# ì…ë‹ˆë‹¤."
        >>> tokens = extract_special_tokens(text)
        >>> print(tokens)  # ['#Person1#', '#PhoneNumber#']
    """
    # #ë¡œ ì‹œì‘í•˜ê³  ëë‚˜ëŠ” íŒ¨í„´ ì°¾ê¸°
    pattern = r'#\w+#'
    tokens = re.findall(pattern, text)

    # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
    unique_tokens = sorted(set(tokens))

    return unique_tokens


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ§ª Testing utility functions...")

    # 1. set_seed í…ŒìŠ¤íŠ¸
    set_seed(42)

    # 2. clean_dialogue í…ŒìŠ¤íŠ¸
    dirty_text = "#Person1#: ì•ˆë…•í•˜ì„¸ìš”\\\\n#Person2#: ë„¤<br>ë°˜ê°‘ìŠµë‹ˆë‹¤ã…‹ã…‹"
    clean_text = clean_dialogue(dirty_text)
    print(f"\nğŸ“ Cleaned text:\n{clean_text}")

    # 3. extract_special_tokens í…ŒìŠ¤íŠ¸
    tokens = extract_special_tokens(clean_text)
    print(f"\nğŸ·ï¸ Special tokens: {tokens}")

    print("\nâœ… All tests passed!")
